<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title><![CDATA[Karry.Blog]]></title>
  
  <link href="/atom.xml" rel="self"/>
  <link href="http://yoursite.com/"/>
  <updated>2016-01-20T11:08:52.375Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name><![CDATA[Karry Huang(黄艺驰)]]></name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title><![CDATA[deep learning review]]></title>
    <link href="http://yoursite.com/2016/01/20/deep-learning-review-1/"/>
    <id>http://yoursite.com/2016/01/20/deep-learning-review-1/</id>
    <published>2016-01-20T11:08:52.000Z</published>
    <updated>2016-01-20T11:08:52.375Z</updated>
    <content type="html"></content>
    <summary type="html">
    
    </summary>
    
  </entry>
  
  <entry>
    <title><![CDATA[deep learning review]]></title>
    <link href="http://yoursite.com/2016/01/19/deep-learning-review/"/>
    <id>http://yoursite.com/2016/01/19/deep-learning-review/</id>
    <published>2016-01-19T02:05:12.000Z</published>
    <updated>2016-02-22T01:47:34.805Z</updated>
    <content type="html"><![CDATA[<p>原文<a href="http://www.nature.com/nature/journal/v521/n7553/pdf/nature14539.pdf" target="_blank" rel="external">Deep Learning Review</a></p>
<p>最新的《Nature》杂志专门为“人工智能+机器学习开辟了一个专题”，发表多篇相关论文，其中包括深度学习三大牛Yann LeCun、Yoshua Bengio和Geoffrey Hinton首次合作的这篇综述文章“Deep Learning”。</p>
<h1 id="摘要">摘要</h1><blockquote>
<p>原文摘要：深度学习可以让那些拥有多个处理层的计算模型来学习具有多层次抽象的数据的表示。这些方法在许多方面带来了显著的改善，包括最先进的语音识别、视觉对象识别、对象检测和许多其他领域，例如药物发现和基因组等。深度学习能够发现大数据中的复杂结构。它是利用BP算法来完成这个发现过程的。BP算法能够指导机器如何从前一层获取误差而改变本层的内部参数，这些内部参数可以用于计算表示。深度卷积网络在处理图像、视频、语音和音频方面带来了突破，而递归网络在处理序列数据，比如文本和语音方面表现出了闪亮的一面。</p>
</blockquote>
<p>机器学习技术在现代社会的各个方面表现出了强大的功能：从Web搜索到社会网络内容过滤，再到电子商务网站上的商品推荐都有涉足，并且它越来越多地出现在消费品中，比如相机和智能手机。</p>
<p>机器学习系统被用来识别图片中的目标，将语音转换成文本，匹配新闻元素，根据用户兴趣提供职位或产品，选择相关的搜索结果。逐渐地，这些应用使用一种叫做深度学习的技术。传统的机器学习技术在处理未加工的数据时，体现出来的能力是有限的。几十年来，想要构建一个模式识别系统或者机器学习系统，需要一个精致的引擎和相当专业的知识来设计一个特征提取器，把原始数据（如图像的像素值）转换成一个适当的内部特征表示或特征向量、子学习系统，通常是一个分类器，对输入的样本进行检测或分类。特征表示学习就是一套给机器灌入原始数据，然后能自动发现需要进行检测和分类的表达的方法。<strong>深度学习就是一种特征学习方法，把原始数据通过一些简单的但是非线性的模型转变为更高层次的，更加抽象的表达。通过足够多的转换的组合，非常复杂的函数也可以被学习。</strong>对于分类任务，高层次的表达能够强化输入数据的区分能力方面，同时削弱不相关因素。比如，一副图像的原始格式是一个像素数组，那么在第一层上的学习特征表达通常指的是在图像的特定位置和方向上有没有边的存在。第二层通常会根据那些边的某些排放而来检测图案，这时候会忽略掉一些边上的一些小的干扰。第三层或许会把那些图案进行组合，从而使其对应于熟悉目标的某部分。随后的一些层会将这些部分再组合，从而构成待检测目标。<strong>深度学习的核心方面是，上述各层的特征都不是利用人工工程来设计的，而是使用一种通用的学习过程从数据中学到的。</strong></p>
<p>深度学习正在取得重大进展，解决了人工智能界的尽最大努力很多年仍没有进展的问题。它已经被证明，它能够擅长发现高维数据中的复杂结构，因此它能够被应用于科学、商业和政府等领域。除了在图像识别、语音识别等领域打破了记录，它还在另外的领域击败了其他机器学习技术，包括预测潜在的药物分子的活性、分子粒子加速器数据、重建大脑回路、预测在非编码DNA突变对基因表达和疾病的影响。也许更令人惊讶的是，深度学习在自然语言理解的各项任务重产生了非常可喜的成果，特别是主题分类、情感分析、自动问答和语言翻译。我们认为，<strong>在不久的将来，深度学习将会取得更多的成功，因为它需要很少的手工工程，它可以很容易受益于可用计算能力和数据量的增加。目前正在为深度神经网络开发的新的学习算法和架构只会加速这一进程。</strong></p>
<h1 id="监督学习">监督学习</h1><p>机器学习中，不论是否是深层，最常见的形式是监督学习。试想一下，我们要建立一个系统，它能够对一个包含了一座房子、一辆汽车、一个人或一个宠物的图像进行分类。我们先收集大量的房子，汽车，人与宠物的图像的数据集，并对每个对象标上它的类别。在训练期间，机器会获取一副图片，然后产生一个输出，这个输出以向量形式的分数来表示，每个类别都有一个这样的向量。我们希望所需的类别在所有的类别中具有最高的得分，但是这在训练之前是不太可能发生的。通过计算一个目标函数可以获得输出分数和期望分数之间的误差（或距离）。然后机器会修改其内部可调用参数，以减少这种误差。这些可调节的参数，通常被称为权值，它们是一些实数，可以被看作是一些“旋钮”，定义了机器的输入输出功能。在典型的深度学习系统中，有可能有数以百万计的样本和权值，和带有标签的样本，用来训练机器。为了正确的调整权值，该学习算法计算每个权值的梯度向量，表示了如果权值增加了一个很小的量，那么误差会增加或减少的量。权值向量然后在梯度矢量的相反方向上进行调整。我们的目标函数，所有训练样本的平均，可以被看作是一种在权值的高维空间上的多变地形。负的梯度矢量表示在该地形中下降方向最快，使其更接近于最小值，也就是平均输出误差最低的地方。</p>
<p>在实际应用中，大部分从业者都使用一种称作随机梯度下降的算法（SGD）。它包含了提供一些输入向量样本，计算输出误差，计算这些样本的平均梯度，然后相应的调整权值。通过提供小的样本集合来重复这个过程以训练网络，直到目标函数停止增长。它会称为随机的是因为小的样本集对于全体样本的平均梯度来说会有噪声估计。这个简单过程通常会找到一组不错的权值，同其他精心设计的优化技术相比，它的速度让人惊奇。训练结束后，系统会通过不同的数据样本——测试集来显示系统的性能。这用于测试机器的泛化能力——对于未训练过的新样本的识别能力。</p>
<p>当前应用中的许多机器学习技术使用的是线性分类器对人工提取的特征进行分类。一个2分类线性分类器会计算特征向量的加权和。当加权和超过一个阈值后，输入样本就会被分配到一个特定的类别中。从20世纪60年代开始，我们就知道了线性分类器只能够把样本分成非常简单的区域，也就是说通过一个超平面把空间分成两部分。</p>
<p>但像图像和语音识别等问题，它们需要的输入-输出函数要对样本中不相关因素的变化不要过于的敏感，如位置的变化、目标的方向或光照，或者语音中音调或语调的变化等，但是需要对于一些特定的微小变化非常敏感（例如，一只白色的狼和跟狼类似的白色狗——萨摩耶德犬之间的差异）。在像素这一级别上，两条萨摩耶德犬在不同的姿势和在不同的环境下的图像可以说差异是非常大的，然而，一只萨摩耶德犬在不同的姿势和在不同的位置并在相似背景下的两个图像可能就非常相似。</p>
<p><img src="http://i.imgur.com/94d4Msd.png" alt="图1 多层神经网络和BP算法"></p>
<p><strong>1.多层神经网络（用连接点表示）可以对输入空间进行整合，使得数据（红色和蓝色线表示的样本）线性可分。</strong>注意输入空间中的规则网格（左侧）是如何被隐藏层转换的（转换后的在右侧）。这个例子中只用了两个输入节点，两个隐藏节点和一个输出节点，但是用于目标识别或自然语言处理的网络通常包含数十个或者数百个这样的节点。获得C.Olah<a href="http://colah.github.io/" target="_blank" rel="external">http://colah.github.io/</a>的许可后重新构建的这个图。</p>
<p><strong>2.链式法则告诉我们两个小的变化（x和y的微小变化，以及y和z的微小变化）是怎样组织到一起的。</strong>x的微小变化量Δx首先会通过乘以∂y/∂x（偏导数）转变成y的变化量Δy。类似地，Δy会给z带来改变Δz。通过链式法则可以将一个方程转化到另外的一个——也就是Δx通过乘以∂y/∂x和∂z/∂y（英文原文为∂z/∂x，系笔误——编辑注）得到Δz的过程。当x，y，z是向量的时候，可以同样处理（使用雅克比矩阵）。</p>
<p><strong>3.具有两个隐层一个输出层的神经网络中计算前向传播的公式。</strong>每个都有一个模块构成，用于反向传播梯度。在每一层上，我们首先计算每个节点的总输入z,z是前一层输出的加权和。然后利用一个非线性函数f(.)来计算节点的输出。简单起见，我们忽略掉了阈值项。神经网络中常用的非线性函数包括了最近几年常用的校正线性单元(ReLU) f(z)=max(0,z)，和更多传统sigmoid函数，比如双曲线正切函数f(z)=(exp(z)-exp(-z))/(exp(z)+exp(-z))和logistic函数f(z)=1/(1+exp(-z))。</p>
<p><strong>4.计算反向传播的公式。</strong>在隐层，我们计算每个输出单元产生的误差，这是由上一层产生的误差的加权和。然后我们输出层的误差通过乘以梯度f(z)转换到输入层。在输出层上，每个节点的误差会用成本函数的微分来计算。如果节点L的成本函数是0.5*(yl-tl)^2，那么节点的误差就是yl-tl，其中tl是期望值。一旦知道了∂E/∂zk的值，节点j的内星权向量wjk就可以通过yj ∂E/∂zk来进行调整。</p>
<p>一个线性分类器或者其他操作在原始像素上的浅层分类器不能够区分后两者，虽然能够将前者归为同一类。这就是为什么浅分类要求有良好的特征提取器用于解决选择性不变性困境——提取器会挑选出图像中能够区分目标的那些重要因素，但是这些因素对于分辨动物的位置就无能为力了。为了加强分类能力，可以使用泛化的非线性特性，如核方法，但这些泛化特征，比如通过高斯核得到的，并不能够使得学习器从学习样本中产生较好的泛化效果。<strong>传统的方法是手工设计良好的特征提取器，这需要大量的工程技术和专业领域知识。但是如果通过使用通过学习过程而得到良好的特性，那么这些都是可以避免的了。这就是深度学习的关键优势。</strong></p>
<p>深度学习的体系结构是简单模块的多层栈，所有（或大部分）模块的目标是学习，还有许多计算非线性输入输出的映射。栈中的每个模块将其输入进行转换，以增加表达的可选择性和不变性。比如说，具有一个5到20层的非线性多层系统能够实现非常复杂的功能，比如输入数据对细节非常敏感——能够区分白狼和萨摩耶德犬，同时又具有强大的抗干扰能力，比如可以忽略掉不同的背景、姿势、光照和周围的物体等。</p>
<h1 id="反向传播来训练多层神经网络">反向传播来训练多层神经网络</h1><p>在最早期的模式识别任务中，研究者的目标一直是使用可以训练的多层网络来替代经过人工选择的特征，虽然使用多层神经网络很简单，但是的出来的解恨糟糕。直到20世纪80年代，使用简单的随机梯度下降来训练多层神经网络，这种糟糕的情况才有所改变。只要网络的输入和内部权值之间的函数相对平滑，使用梯度下降就奏效，梯度下降方法是在70年代到80年代期间由不同的研究团队独立发明的。</p>
<p>用来求解目标函数关于多层神经网络权值梯度的反向传播算法（BP）只是一个用来求导的链式法则的具体应用而已。<strong>反向传播算法的核心思想是：目标函数对于某层输入的导数（或者梯度）可以通过向后传播对该层输出（或者下一层输入）的导数求得（如图1）。</strong>反向传播算法可以被重复的用于传播梯度通过多层神经网络的每一层：从该层神经网络的最顶层输出（也就是改网络产生预测的那一层）一直到该多层神经网络的最底层（也就是被接受外部输入的那一层），一旦这些关于（目标函数对）每层输入的导数求解完，我们就可以求解每一层上面的（目标函数对）权值的梯度了。</p>
<p>很多深度学习的应用都是使用前馈式神经网络（如图1），该神经网络学习一个从固定大小输入（比如输入是一张图）到固定大小输出（例如，到不同类别的概率）的映射。从第一层到下一层，计算前一层神经元输入数据的权值的和，然后把这个和传给一个非线性激活函数。当前最流行的非线性激活函数是rectified linear unit(ReLU),函数形式：f(z)=max(z,0)。过去的几十年中，神经网络使用一些更加平滑的非线性函数，比如tanh(z)和1/(1+exp(-z))，但是ReLU通常会让一个多层神经网络学习的更快，也可以让一个深度网络直接有监督的训练（不需要无监督的pre-train）。</p>
<p>达到之前那种有pre-train的效果。通常情况下，输入层和输出层以外的神经单元被称为隐藏单元。隐藏层的作用可以看成是使用一个非线性的方式打乱输入数据，来让输入数据对应的类别在最后一层变得线性可分。</p>
<p>在20世纪90年代晚期，神经网络和反向传播算法被大多数机器学习团队抛弃，同时也不受计算机视觉和语音识别团队的重视。人民普遍认为，<strong>学习有用的、多级多层次结构的、使用较少先验知识进行特征提取的这些方法都不靠谱。确切的说是因为简单的梯度下降会让整个优化陷入到不好的局部最小解。</strong></p>
<p>实践中，如果在大的网络中，不管使用什么样的初始化条件，局部最小解并不算什么大问题，系统总是得到效果差不多的解。最近的理论和实验表明，局部最小值还真不是啥大问题。相反，解空间中充满了大量的鞍点（梯度为0的点），同时鞍点周围大部分曲面都是往上的。所以这些算法就算是陷入例如这些局部最小值，关系也不太大。</p>
<p>2006年前后，CIFAR（加拿大高级研究院）把一些研究者聚集在一起，人们对深度前馈式神经网络重新燃起了兴趣。研究者们提出了一种<strong>非监督的学习方法</strong>，这种方法可以创建一些网络层来检测特征而不使用带标签的数据，这些网络层可以用来重构或者对特征检测器的活动进行建模。通过预训练过程，深度网络的权值可以被初始化为有意思的值。然后一个输出层被添加到该网络的顶部，并且使用标准的反向传播算法进行微调。这个工作对手写体数字的识别以及行人预测任务产生了显著的效果，尤其是带标签的数据非常少的时候。</p>
<p>使用这种与训练方法做出来的第一个比较大的应用是关于<strong>语音识别</strong>的，并且是在<strong>GPU</strong>上做的，这样做是因为写代码很方便，并且在训练的时候可以得到10倍或者20倍的加速。2009年，这种方法被用来隐射短时间的系数窗口，该系统窗口是提取声波并转换为一组概率数字。它在一组使用很少词汇的标准的语音识别基准测试程序上达到了惊人的效果，然后又迅速被发展到另外一个更大的数据集上，同时也取得了惊人的效果。从2009年到2012年底，较大的语音团队开发了这种深度网络的多个版本并且已经被用到了安卓手机上。对于小的数据集来说，无监督的预训练可以防止过拟合，同时可以带来更好的泛化性能（当有标签的样本很少的时候）。一旦深度学习技术重新恢复，这种预训练只有在数据集较少的时候才需要。</p>
<p>然后，还有一种深度前馈式神经网络，这种网络更易于训练并且比那种全连接的神经网络的泛化性能更好。这就是卷积神经网络（CNN）。当人们对神经网络不感兴趣的时候，卷积神经网络在实践中却取得了很多成功，如今它被计算机视觉团队广泛使用。</p>
<h1 id="卷积神经网络">卷积神经网络</h1><p>卷积神经网络被设计用来处理到多维数据数据的，比如一个有3个包含了像素值2-D图像组合成的一个具有3个颜色的彩色图像。很多数据形态都是有这种多维数组的：1D用来表示信号和序列包括语言，2D用来表示图像或者声音，3D用来表示视频或者有声音的图像。卷积神经网络使用4个关键的想法来利用自然信号的属性、；局部连接、权值共享、池化以及多网络层的使用。</p>
<p><img src="http://i.imgur.com/lqqL8yI.png" alt="图2"></p>
<p>一个典型的卷积神经网络结构（如图2）是由一系列的过程组成的。最初的几个阶段是由卷积层和池化组成，卷积层的单元被组织在特征图中，在特征图中，每一个单元通过一组叫做滤波器的权值被连接到上一层的特征图的一个局部块，然后这个局部加权和被传给一个非线性函数，比如ReLU。在一个特征图中的全部单元享用相同的过滤器，不同层的特征图使用不同的过滤器。使用这种结构出于两方面的原因。首先，在数组数据中，比如图像数据，一个值的附近的值经常是高度相关的，可以形成比较容易被探测到的有区分性的局部特征。其次，不同位置局部统计特征不太相关的，也就是说，在一个地方出现的某个特征，也可能出现在别的地方，所以不同位置的单元可以共享权值以及可以探测相同的样本。在数学上，这种由一个特征图执行的过滤操作是一个离线的卷积，卷积神经网络也是这么得名而来。</p>
<p>卷积层的作用是探测上一层特征的局部连接，而池化层的作用是在语义上把相似的特征合并起来，这是因为形成一个主题的特征的相对位置不太一样。一般地，池化单元计算特征图中的一个局部块的最大值，相邻的池化单元通过移动一行或者一列来从小块上读取数据，因为这样做就减少的表达的维度以及对数据的平移不变性。两三个这种的卷积、非线性变换以及池化被串起来，后面再加上一个更多卷积和全连接层。在卷积神经网络上进行反向传播算法和在一般的深度网络上是一样的，可以让所有的在过滤器中的权值得到训练。</p>
<p>深度神经网络利用的很多自然信号是层级组成的属性，在这种属性中高级的特征是通过对低级特征的组合来实现的。在图像中，局部边缘的组合形成基本图案，这些图案形成物体的局部，然后再形成物体。这种层级结构也存在于语音数据以及文本数据中，如电话中的声音，因素，音节，文档中的单词和句子。当输入数据在前一层中的位置有变化的时候，池化操作让这些特征表示对这些变化具有鲁棒性。</p>
<p>卷积神经网络中的卷积和池化层灵感直接来源于视觉神经科学中的简单细胞和复杂细胞。这种细胞的是以LNG-V1-V2-V4-IT这种层级结构形成视觉回路的。当给一个卷积神经网络和猴子一副相同的图片的时候，卷积神经网络展示了猴子下颞叶皮质中随机160个神经元的变化。卷积神经网络有神经认知的根源，他们的架构有点相似，但是在神经认知中是没有类似反向传播算法这种端到端的监督学习算法的。一个比较原始的1D卷积神经网络被称为时延神经网络，可以被用来识别语音以及简单的单词。</p>
<p>20世纪90年代以来，基于卷积神经网络出现了大量的应用。最开始是用时延神经网络来做语音识别以及文档阅读。这个文档阅读系统使用一个被训练好的卷积神经网络和一个概率模型，这个概率模型实现了语言方面的一些约束。20世纪90年代末，这个系统被用来美国超过10%的支票阅读上。后来，微软开发了基于卷积神经网络的字符识别系统以及手写体识别系统。20世纪90年代早期，卷积神经网络也被用来自然图形中的物体识别，比如脸、手以及人脸识别（face recognition ）。</p>
<h1 id="使用深度卷积网络进行图像理解">使用深度卷积网络进行图像理解</h1><p>21世纪开始，卷积神经网络就被成功的大量用于检测、分割、物体识别以及图像的各个领域。这些应用都是使用了大量的有标签的数据，比如交通信号识别，生物信息分割，面部探测，文本、行人以及自然图形中的人的身体部分的探测。近年来，卷积神经网络的一个重大成功应用是人脸识别。</p>
<p>值得一提的是，图像可以在像素级别进行打标签，这样就可以应用在比如自动电话接听机器人、自动驾驶汽车等技术中。像Mobileye以及NVIDIA公司正在把基于卷积神经网络的方法用于汽车中的视觉系统中。其它的应用涉及到自然语言的理解以及语音识别中。</p>
<p><img src="http://i.imgur.com/Ojrf9s3.png" alt="图3 从图像到文字"><br><img src="http://i.imgur.com/SSqO8EX.png" alt=""></p>
<p>尽管卷积神经网络应用的很成功，但是它被计算机视觉以及机器学习团队开始重视是在2012年的ImageNet竞赛。在该竞赛中，深度卷积神经网络被用在上百万张网络图片数据集，这个数据集包含了1000个不同的类。该结果达到了前所未有的好，几乎比当时最好的方法降低了一半的错误率。这个成功来自有效地利用了GPU、ReLU、一个新的被称为dropout的正则技术，以及通过分解现有样本产生更多训练样本的技术。这个成功给计算机视觉带来一个革命。如今，卷积神经网络用于几乎全部的识别和探测任务中。最近一个更好的成果是，利用卷积神经网络结合回馈神经网络用来产生图像标题。</p>
<p>如今的卷积神经网络架构有10-20层采用ReLU激活函数、上百万个权值以及几十亿个连接。然而训练如此大的网络两年前就只需要几周了，现在硬件、软件以及算法并行的进步，又把训练时间压缩到了几小时。</p>
<p>基于卷积神经网络的视觉系统的性能已经引起了大型技术公司的注意，比如Google、Facebook、Microsoft、IBM，yahoo！、Twitter和Adobe等，一些快速增长的创业公司也同样如是。</p>
<p>卷积神经网络很容易在芯片或者现场可编程门阵列（FPGA）中高效实现，许多公司比如NVIDIA、Mobileye、Intel、Qualcomm以及Samsung，正在开发卷积神经网络芯片，以使智能机、相机、机器人以及自动驾驶汽车中的实时视觉系统成为可能。</p>
<h1 id="分布式特征表示与语言处理">分布式特征表示与语言处理</h1><p>与不使用分布式特征表示（distributed representations ）的经典学习算法相比，深度学习理论表明深度网络具有两个不同的巨大的优势。这些优势来源于网络中各节点的权值，并取决于具有合理结构的底层生成数据的分布。首先，学习分布式特征表示能够泛化适应新学习到的特征值的组合（比如，n元特征就有2n种可能的组合）。其次，深度网络中组合表示层带来了另一个指数级的优势潜能（指数级的深度）。</p>
<p>多层神经网络中的隐层利用网络中输入的数据进行特征学习，使之更加容易预测目标输出。下面是一个很好的示范例子，比如将本地文本的内容作为输入，训练多层神经网络来预测句子中下一个单词。内容中的每个单词表示为网络中的N分之一的向量，也就是说，每个组成部分中有一个值为1其余的全为0。在第一层中，每个单词创建不同的激活状态，或单词向量（如图4）。在语言模型中，网络中其余层学习并转化输入的单词向量为输出单词向量来预测句子中下一个单词，可以通过预测词汇表中的单词作为文本句子中下一个单词出现的概率。网络学习了包含许多激活节点的、并且可以解释为词的独立特征的单词向量，正如第一次示范的文本学习分层表征文字符号的例子。这些语义特征在输入中并没有明确的表征。而是在利用“微规则”（‘micro-rules’,本文中直译为：微规则）学习过程中被发掘，并作为一个分解输入与输出符号之间关系结构的好的方式。当句子是来自大量的真实文本并且个别的微规则不可靠的情况下，学习单词向量也一样能表现得很好。利用训练好的模型预测新的事例时，一些概念比较相似的词容易混淆，比如星期二（Tuesday）和星期三（Wednesday），瑞典（Sweden）和挪威（Norway）。这样的表示方式被称为分布式特征表示，因为他们的元素之间并不互相排斥，并且他们的构造信息对应于观测到的数据的变化。这些单词向量是通过学习得到的特征构造的，这些特征不是由专家决定的，而是由神经网络自动发掘的。从文本中学习得单词向量表示现在广泛应用于自然语言中。</p>
<p>特征表示问题争论的中心介于对基于逻辑启发和基于神经网络的认识。在逻辑启发的范式中，一个符号实体表示某一事物，因为其唯一的属性与其他符号实体相同或者不同。该符号实例没有内部结构，并且结构与使用是相关的，至于理解符号的语义，就必须与变化的推理规则合理对应。相反地，神经网络利用了大量活动载体、权值矩阵和标量非线性化，来实现能够支撑简单容易的、具有常识推理的快速“直觉”功能。</p>
<p>在介绍神经语言模型前，简述下标准方法，其是基于统计的语言模型，该模型没有使用分布式特征表示。而是基于统计简短符号序列出现的频率增长到N（N-grams，N元文法）。可能的N-grams的数字接近于VN，其中V是词汇表的大小，考虑到文本内容包含成千上万个单词，所以需要一个非常大的语料库。N-grams将每个单词看成一个原子单元，因此不能在语义相关的单词序列中一概而论，然而神经网络语言模型可以，是因为他们关联每个词与真是特征值的向量，并且在向量空间中语义相关的词彼此靠近（图4）。</p>
<p><img src="http://i.imgur.com/zRzAmPm.png" alt="图4"></p>
<h1 id="递归神经网络">递归神经网络</h1><p>首次引入反向传播算法时，最令人兴奋的便是使用递归神经网络（recurrent neural networks，下文简称RNNs）训练。对于涉及到序列输入的任务，比如语音和语言，利用RNNs能获得更好的效果。RNNs一次处理一个输入序列元素，同时维护网络中隐式单元中隐式的包含过去时刻序列元素的历史信息的“状态向量”。如果是深度多层网络不同神经元的输出，我们就会考虑这种在不同离散时间步长的隐式单元的输出，这将会使我们更加清晰怎么利用反向传播来训练RNNs（如图5，右）。</p>
<p><img src="http://i.imgur.com/clPde5Z.png" alt="图5"></p>
<p>RNNs是非常强大的动态系统，但是训练它们被证实存在问题的，因为反向传播的梯度在每个时间间隔内是增长或下降的，所以经过一段时间后将导致结果的激增或者降为零。</p>
<p>由于先进的架构和训练方式，RNNs被发现可以很好的预测文本中下一个字符或者句子中下一个单词，并且可以应用于更加复杂的任务。例如在某时刻阅读英语句子中的单词后，将会训练一个英语的“编码器”网络，使得隐式单元的最终状态向量能够很好地表征句子所要表达的意思或思想。这种“思想向量”（thought vector）可以作为联合训练一个法语“编码器”网络的初始化隐式状态（或者额外的输入），其输出为法语翻译首单词的概率分布。如果从分布中选择一个特殊的首单词作为编码网络的输入，将会输出翻译的句子中第二个单词的概率分布，并直到停止选择为止。总体而言，这一过程是根据英语句子的概率分布而产生的法语词汇序列。这种简单的机器翻译方法的表现甚至可以和最先进的（state-of-the-art）的方法相媲美，同时也引起了人们对于理解句子是否需要像使用推理规则操作内部符号表示质疑。这与日常推理中同时涉及到根据合理结论类推的观点是匹配的。</p>
<p>类比于将法语句子的意思翻译成英语句子，同样可以学习将图片内容“翻译”为英语句子（如图3）。这种编码器是可以在最后的隐层将像素转换为活动向量的深度卷积网络（ConvNet）。解码器与RNNs用于机器翻译和神经网络语言模型的类似。近来，已经掀起了一股深度学习的巨大兴趣热潮（参见文献[86]提到的例子）。</p>
<p>RNNs一旦展开（如图5），可以将之视为一个所有层共享同样权值的深度前馈神经网络。虽然它们的目的是学习长期的依赖性，但理论的和经验的证据表明很难学习并长期保存信息。</p>
<p>为了解决这个问题，一个增大网络存储的想法随之产生。采用了特殊隐式单元的LSTM（long short-termmemory networks）被首先提出，其自然行为便是长期的保存输入。一种称作记忆细胞的特殊单元类似累加器和门控神经元：它在下一个时间步长将拥有一个权值并联接到自身，拷贝自身状态的真实值和累积的外部信号，但这种自联接是由另一个单元学习并决定何时清除记忆内容的乘法门控制的。</p>
<p>LSTM网络随后被证明比传统的RNNs更加有效，尤其当每一个时间步长内有若干层时，整个语音识别系统能够完全一致的将声学转录为字符序列。目前LSTM网络或者相关的门控单元同样用于编码和解码网络，并且在机器翻译中表现良好。</p>
<p>过去几年中，几位学者提出了不同的提案用于增强RNNs的记忆模块。提案中包括神经图灵机，其中通过加入RNNs可读可写的“类似磁带”的存储来增强网络，而记忆网络中的常规网络通过联想记忆来增强。记忆网络在标准的问答基准测试中表现良好，记忆是用来记住稍后要求回答问题的事例。</p>
<p>除了简单的记忆化，神经图灵机和记忆网络正在被用于那些通常需要推理和符号操作的任务，还可以教神经图灵机“算法”。除此以外，他们可以从未排序的输入符号序列（其中每个符号都有与其在列表中对应的表明优先级的真实值）中，学习输出一个排序的符号序列。可以训练记忆网络用来追踪一个设定与文字冒险游戏和故事的世界的状态，回答一些需要复杂推理的问题。在一个测试例子中，网络能够正确回答15句版的《指环王》中诸如“Frodo现在在哪？”的问题。</p>
<h1 id="深度学习的未来展望">深度学习的未来展望</h1><p>无监督学习对于重新点燃深度学习的热潮起到了促进的作用，但是纯粹的有监督学习的成功盖过了无监督学习。在本篇综述中虽然这不是我们的重点，我们还是期望无监督学习在长期内越来越重要。无监督学习在人类和动物的学习中占据主导地位：我们通过观察能够发现世界的内在结构，而不是被告知每一个客观事物的名称。</p>
<p>人类视觉是一个智能的、基于特定方式的利用小或大分辨率的视网膜中央窝与周围环绕区域对光线采集成像的活跃的过程。我们期望未来在机器视觉方面会有更多的进步，这些进步来自那些端对端的训练系统，并结合ConvNets和RNNs，采用增强学习来决定走向。结合了深度学习和增强学习的系统正处在初期，但已经在分类任务中超过了被动视频系统，并在学习操作视频游戏中产生了令人印象深刻的效果。</p>
<p>在未来几年，自然语言理解将是深度学习做出巨大影响的另一个领域。我们预测那些利用了RNNs的系统将会更好地理解句子或者整个文档，当它们选择性地学习了某时刻部分加入的策略。</p>
<p>最终，在人工智能方面取得的重大进步将来自那些结合了复杂推理表示学习（representation learning ）的系统。尽管深度学习和简单推理已经应用于语音和手写字识别很长一段时间了，我们仍需要通过操作大量向量的新范式来代替基于规则的字符表达式操作。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>原文<a href="http://www.nature.com/nature/journal/v521/n7553/pdf/nature14539.pdf" target="_blank" rel="external">Deep Learning Review</a></]]>
    </summary>
    
      <category term="deep learning" scheme="http://yoursite.com/tags/deep-learning/"/>
    
      <category term="deep learning" scheme="http://yoursite.com/categories/deep-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[HTKbook第一章]]></title>
    <link href="http://yoursite.com/2015/12/16/HTK-learning-notes/"/>
    <id>http://yoursite.com/2015/12/16/HTK-learning-notes/</id>
    <published>2015-12-16T07:10:36.000Z</published>
    <updated>2016-01-09T09:39:04.809Z</updated>
    <content type="html"><![CDATA[<p>来源：<a href="http://htk.eng.cam.ac.uk/" title="HTKbook" target="_blank" rel="external">HTKbook</a></p>
<h1 id="第一章_HTK基础">第一章    HTK基础</h1><p><img src="http://i.imgur.com/rmByzAM.png" alt="图1"></p>
<p>HTK是一个构建隐马尔科夫模型（HMMs）的工具。如图1所示，它主要包括两个阶段：</p>
<ol>
<li><p>HTK training tools:通过训练样本估计HMMs的参数及其相关的录音文本(transcriptions)</p>
</li>
<li><p>HTK recognition tools:测试的未知文本语音由识别器转录(transcribe)</p>
</li>
</ol>
<h2 id="1-1_HMMS基本原则">1.1 HMMS基本原则</h2><p><img src="http://i.imgur.com/NFWJEjJ.png" alt=""></p>
<p>如图1.1所示，语音识别系统通常会假设语音信号是把消息编码成由一个或多个符号组成的序列(symbols)。识别的过程就是解码，即把测试语音还原成强调的符号序列，连续的语音波形首先被转换为一串等长的离散参数向量。假设这个参数向量的序列恰好是语音波形的最佳表示，参数向量是以单个向量持续时间为基础，通常是10ms，在这个时间内语音波形可以认为是不变的。常用的典型参数是平滑的频谱(smoothed spectra)、LPC(linear prediction coefficients)+其他从中推出的表示。</p>
<p>识别器(recogniser)的作用就是把speech vectors sequences映射为underlying symbol sequences。这里有两个问题：</p>
<p>问题一：</p>
<ol>
<li><p>从符号到语音的映射不是一对一的，因为不同的强调符号会发出相似的语音。而且由于说话人、说话态度、环境等的不同，最终的语音波形也会千差万别。</p>
</li>
<li><p>符号间的边界不能从语音波形中明显地识别出。</p>
</li>
</ol>
<p>因此，不能把语音波形当成一串级联的静态模式(concatenated static patterns)。</p>
<p>问题二：</p>
<p>不知道单词边界的位置。这个问题可以通过增加孤立词识别这一条件避免。如图1.2所示，语音波形与单个符号（例如，单词）对应，单词都是从一个固定的字典里选出。所以，首先解决的是孤立词识别问题。</p>
<h2 id="1-2_孤立词识别(Isolated_Word_Recognition)">1.2 孤立词识别(Isolated Word Recognition)</h2><p><img src="http://i.imgur.com/x55wftJ.png" alt=""></p>
<p>令每个发音单词用语音向量序列或观察向量O表示，定义为：<br> <img src="http://i.imgur.com/BQrbeF2.png" alt="1.1"><br>                                                 (1.1)</p>
<p>其中 表示在 时刻观察到的语音向量。就可以认为孤立词识别问题是在计算：</p>
<p><img src="http://i.imgur.com/9daVzmF.png" alt="">                 (1.2)</p>
<p>其中 表示第 个词典词。这个概率不是直接计算的，而是由贝叶斯公式给出：</p>
<p><img src="http://i.imgur.com/LZq89xi.png" alt="">                (1.3)</p>
<p>因此，给定先验概率<img src="http://i.imgur.com/JzhPXOG.png" alt=""> ，最可能的发音单词就仅仅取决于概率<img src="http://i.imgur.com/hYqtuA1.png" alt=""> 。给定观察序列<img src="http://i.imgur.com/7E2TWrU.png" alt=""> 的维数，从发音单词的样本直接计算联合条件概率 是很难实现的。然而，如果一个单词的参数模型假设是马尔可夫模型，当估计条件观察值密度<img src="http://i.imgur.com/vnQue2H.png" alt=""> 的问题被估计马尔可夫参数的简单问题代替，由观察向量计算<img src="http://i.imgur.com/cLhIAYi.png" alt=""> 就可以实现了。</p>
<p>当然，所有的这些都要假设每个模型的参数{aij}和{bij｝是已知的。这里依赖于HMM框架的魅力和能力。假定一组训练样本对应一个特定模型，根据一个稳定有效的重估过程可自动求出该模型的参数。因此，当每个单词都有足够多的具有代表性的样本时，一个HMM就可以构造出来了，其中隐含了对真实语音的所有的内在变化的模拟。图1.4描述了HMM在孤立词识别中的应用。首先，在词典中只有“one”，“two”，“three”三个单词的情况下，用各个词典词的许多样本训练出对应的HMM。然后，为了识别未知单词，计算各个模型生成该单词的似然，找出最有可能的一个模型，这就识别出了这一未知的单词。</p>
<p><img src="http://i.imgur.com/46P6F1P.jpg" alt=""></p>
<h2 id="1-3_输出概率">1.3 输出概率</h2><p><img src="http://i.imgur.com/HMQWRGl.png" alt=""><br><img src="http://i.imgur.com/CtTi6kJ.png" alt=""></p>
<h2 id="1-4_Baum-Welch重估">1.4 Baum-Welch重估</h2><p><img src="http://i.imgur.com/mXKxcti.png" alt=""><br><img src="http://i.imgur.com/y5G2JW3.png" alt=""><br><img src="http://i.imgur.com/dsTKCFq.png" alt=""><br><img src="http://i.imgur.com/0Md3SfB.png" alt=""><br><img src="http://i.imgur.com/bqR6YaU.png" alt=""><br><img src="http://i.imgur.com/cfe4oU3.png" alt=""><br><img src="http://i.imgur.com/C23bo4w.png" alt=""><br><img src="http://i.imgur.com/Hnz3waP.png" alt=""></p>
<h2 id="1-5_识别和Viterbi解码">1.5 识别和Viterbi解码</h2><p><img src="http://i.imgur.com/Ppe2Mnd.png" alt=""><br><img src="http://i.imgur.com/qqLlHCc.png" alt=""><br><img src="http://i.imgur.com/Xw7Scsp.png" alt=""></p>
<h2 id="1-6_连续语音识别">1.6 连续语音识别</h2><p>现在回到图1.1所示的语音产生和识别的概念模型，需要明白的是推广到连续语音只是简单地让HMM有序地连接在一起。序列中的每个模型和隐藏的符号直接对应。这些符号可能是针对连接语音识别（Connected Speech Recognition）的整个单词，或者是针对连续语音识别的子词（例如音素）。为什么存在没有输出的入口状态和出口状态呢？现在就很明显了，因为这些状态可以用来将各个模型连接在一起。</p>
<pre><code>然而还得克服一些实际问题中遇到的困难。连续语音的训练数据必须包括连续语料，而一般对应到子词模型的每段语音的切分边界都是不知道的。在实际过程中，通常是人工标注少量的数据边界，这样，一个模型对应的所有语音片段都可以提取出来，也可以进行上述的孤立词训练。然而，用这种方法得到的数据是很有限的，并且模型估计结果也很差。此外，即使有了大量的数据，人工强行标记的边界也可能不是HMM使用的最佳边界。因此，在HTK中使用HInit和HRest初始化子词模型可视为引导（<span class="keyword">bootstrap）操作 </span>。主要的训练阶段还是用工具HERest来完成，它用于嵌入式训练（Embedded Training）。
</code></pre><p>同孤立词训练一样，嵌入式训练也使用Baum-Welch算法，不同的是前者对各个模型单独训练，而后者是所有模型并行训练。它具体的工作步骤如下：</p>
<ol>
<li>为所有模型的所有参数的accumulators分配空间，并置0。</li>
<li>得到下一个训练语料。</li>
<li>有序地联结和训练语料的符号脚本相对应的所有HMM，构造出一个复合的HMM。</li>
<li>对这个复合的HMM计算前向-后向概率。在复合模型中，包含不输出的状态，因此前向概率和后向概率的计算有所改变，但变动很小，这在第八章中将详细地讨论。</li>
<li>使用前向和后向概率计算在每一帧的状态占有概率，并用通常的方法更新accumulators。</li>
<li>从第二步开始重复上述操作，直到处理完所有的训练语料。</li>
<li><p>用accumulators计算所有HMM的新的参数估计值。<br>多次重复这些步骤，直到达到要求的收敛为止。需要指出的是，虽然这个过程没有要求训练数据中的符号边界位置，但每个训练语料的符号脚本还是必须的。<br>对于训练子词模型，Baum-Welch算法需要做的扩展相对Viterbi算法需要做的扩展来说要少一些 。<br>在HTK中，Viterbi算法的另一表述形式为Token Passing Model 。简单地说，Token Passing Model明确地给出状态对齐路径的概念。假设在 时刻HMM的每个状态 对应了一个可移动的token，该token在其它信息中包含了局部log概率 。那么这一token就表示了观测序列 … 与在 时刻进入状态 的模型之间的一个局部匹配。这时可用token passing 算法来代替公式(1.31)表示的路径扩充算法，它在每一帧 都要执行。这个算法的主要步骤如下：</p>
</li>
<li><p>拷贝状态 中的每一个token，传给到所有的连接的状态 ，使用 增加所拷贝的token的log概率。</p>
</li>
<li><p>检查每个状态的token，留下最大概率的token，扔掉其他token。<br>在实际中，处理不输出的状态时需要一些修改，但这些比较简单，如果token在入口状态，就假设路径延伸到 ，而在出口状态则延伸到 。<br>用Token Passing Model的关键是因为它能很简单地扩展到连续语音的情形。假设HMM序列是一个有限状态网络。例如，图1.7显示了一个简单的网络，每个单词定义为基于音素的HMM序列，所有的单词是放在一个圆环里。在这个网络里，椭圆框表示HMM实例，方框表示word-end节点。这个复合网络正是一个大的HMM，应用了上面的Token Passing 算法。现在唯一的不同是比最优token的log概率需要更多的信息。当最优token到达语音结尾时，为了恢复识别出的模型序列，我们必须知道它通过网络的路径。</p>
<pre><code>!<span class="attr_selector">[]</span>(<span class="attribute">http</span>:<span class="comment">//i.imgur.com/BNlnrDx.png)</span>
</code></pre><p>穿过网络的token路径的历史记录可以按照下面方式有效地记录下来。每个token带有一个“Word End Link”指针，当一个token从一个单词的出口状态（用穿过word-end结点表示）传到另一个单词的入口状态产生一个路径时，这一传输表示了一个可能的单词边界。因此生成一个称为“Word Link Record”（WLR）的记录存储该单词的刚刚出现的token和token链的当前值。那么这个实际的token链就是用一个新的WLR指针来代替，图1.8说明了这一过程。<br>一旦处理完所有的未知语音，带有最优token（也就是最大log概率的token）链的WLR能够追溯得到最优匹配单词序列。同时如有需要，也能得到单词边界的位置。<br><img src="http://i.imgur.com/Grl1y9F.png" alt=""><br>上面针对连续语音的Token Passing算法描述仅仅用于记录单词序列。如果需要，该原理还能用来记录在模型和状态级的决策，也能保存每个单词边界上更多的最优路径。这样就为生成hypotheses（译者注：意为可能的识别结果）的lattice（译者注：网格）提供了可能，lattice比单Best输出更有用。基于这个思想的算法称为lattice N-best。因为每个状态一个token，限制了可能得到的不同token历史记录的数量，所以他们不是最合适的。若每个模型状态对应多个token，并且如果认为来自不同前序单词的token是不同的，就可以避免上述限制。这类算法称为word N-best 算法，经验表明它的性能可以和最优的N-best算法相当。<br>上面概述了用在HTK中的Token Passing的主要思想。这些算法植入到了库模块HNet和HRec中，它们会被识别工具HVite调用。它们提供单个和多个Token Passing识别，single-best输出，网格输出，N-best列表，支持上下文相关cross-word，lattice rescoring和forced alignment。</p>
</li>
</ol>
<h2 id="1-7_发音人自适应">1.7 发音人自适应</h2><p>虽然上面所讲的训练和识别技术能够产生出高效的识别系统，但如果对特定发音人的特征定制HMM，那么这些系统的效果将得到进一步的提高。HTK提供了HEAdapt和HVite工具，它们用少量的enrollment或自适应数据来执行自适应。这两个工具的不同之处在于，HEAdapt进行离线有监督的适应，而HVite识别自适应数据并使用生成的脚本来进行自适应。通常，HEAdapt提供的有监督的自适应更稳定一些，但是给定一个初始的已经很好地训练过的模型集，HVite仍然能显著地改善其效果。在第九章将描述自适应的细节及它在HTK中的使用。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>来源：<a href="http://htk.eng.cam.ac.uk/" title="HTKbook" target="_blank" rel="external">HTKbook</a></p>
<h1 id="第一章_HTK基础">第一章    HTK基础</h1]]>
    </summary>
    
      <category term="HTK" scheme="http://yoursite.com/tags/HTK/"/>
    
      <category term="HTK" scheme="http://yoursite.com/categories/HTK/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[TensorFlow白皮书【译】]]></title>
    <link href="http://yoursite.com/2015/11/23/TensorFlowWhitePaper/"/>
    <id>http://yoursite.com/2015/11/23/TensorFlowWhitePaper/</id>
    <published>2015-11-23T12:16:35.000Z</published>
    <updated>2015-12-02T08:52:15.994Z</updated>
    <content type="html"><![CDATA[<h1 id="TensorFlow:大规模机器学习的异构分布式系统">TensorFlow:大规模机器学习的异构分布式系统</h1><blockquote>
<p>TensorFlow从名称上看就是两个部分——张量tensor和流flow。非常形象的组合。众所周知，矩阵已经成为机器学习中的基础单元，若干的针对矩阵的计算优化使得现如今的机器学习成为可能。而一些矩阵的方法也是一些重要的机器学习算法的基础。张量就是矩阵概念的推广，其表示更多维度的矩阵。而计算流是一种抽象过程，在如今的深度学习领域，这种一层层地计算可以很形象地看做是张量在计算模型上的流动。而这里的流可以看做是更加一般的计算过程，可以在不同的层级间跨越式流动。</p>
</blockquote>
<p>本文作者均来自Google Research:Martín Abadi, Ashish Agarwal, Paul Barham, Eugene Brevdo, Zhifeng Chen, Craig Citro, Greg S. Corrado, Andy Davis, Jeffrey Dean, Matthieu Devin, Sanjay Ghemawat, Ian Goodfellow, Andrew Harp, Geoffrey Irving, Michael Isard, Yangqing Jia, Rafal Jozefowicz, Lukasz Kaiser, Manjunath Kudlur, Josh Levenberg, Dan Mane, Rajat Monga, Sherry Moore, Derek Murray, Chris Olah, Mike Schuster, Jonathon Shlens, Benoit Steiner, Ilya Sutskever, Kunal Talwar, Paul Tucker, Vincent Vanhoucke, Vijay Vasudevan, Fernanda Viegas, Oriol Vinyals, Pete Warden, Martin Wattenberg, Martin Wicke, Yuan Yu, and Xiaoqiang Zheng</p>
<h1 id="摘要">摘要</h1><p>TensorFlow[1]是一个表达机器学习算法的接口，并且是执行算法的实现框架。使用TensorFlow表示的计算可以在众多异构的系统上方便地移植，从移动设备如手机或者平板电脑到成千的GPU计算集群上都可以执行。该系统灵活，可以被用来表示很多的算法包括，深度神经网络的训练和推算算法，也已经被用作科研和应用机器学习系统在若干的计算机科学领域或者其他领域中，例如语言识别、计算机视觉、机器人、信息检索、自然语言理解、地理信息抽取和计算药物发现。该论文描述了TensorFlow的接口和我们在Google构建的结构实现。TensorFlow API和参考实现都已经作为开源项目按照Apache2.0协议在2015年11月发布，可以在<a href="http://www.tensorflow.org/" target="_blank" rel="external">这里</a>查看。</p>
<h1 id="1_引言">1 引言</h1><p>Google大脑项目开始于2011年，目的是探索在科研和Google的产品中超大规模深度神经网络的使用。作为这个项目的早期工作，我们构建了DistBelif——第一代的可扩展分布式训练和推断系统[14]，这个系统工作得很不错。我们和其他Google的同事使用DistBelief进行了广泛的研究包括非监督学习[31]、语言表示[35,52]、图像分类模型和目标检测[16,48]，视频分类[27]、语音识别[56,21,20]、序列预测[47]、Go 的移动选择[34]、行人检测[2]、强化学习[38] 等等。另外，和 Google Brain 团队合作中，超过 50 个 Google 内部的团队和其他 Alphabet 公司也已经部署了使用 DistBelief 的深度神经网络在众多产品中，包括 Google Search[11]、广告产品、语音识别系统[50,6,46]、Google Photos[43]、Google Maps 和 街景[19]、Google 翻译[18]、Youtube 和很多其他的产品。</p>
<p>基于我们使用 DistBelief 的经验和对于期望用来训练和使用神经网络的系统特性和需求更加完备地理解，我们构建了 TensorFlow——第二代大规模机器学习模型的实现和部署的系统。TensorFlow 使用通过类似数据流模型的计算，将这些计算映射到不同的硬件平台例如使用包含一个或者多个 GPU 显卡的装有 Android 和 iOS 的单个机器上进行推断，到运行在数百台包含数千个 GPU 的大规模系统训练和推断。拥有一个单一的系统可以扩展分布到众多的平台上可以大大简化真实场景中机器学习系统的使用，正如我们在用分离的系统进行大规模训练和小规模的部署，会产生巨大的维护代价和较差的抽象效果。TensorFlow 的计算被表示为含状态的数据流图（在第二节详细讲解），我们聚焦在让这个系统足够灵活能够快速地实验研究中产生的新模型，并同时充分地提升产品级训练的性能和部署机器学习模型健壮性。为扩展神经网络训练搞更大的部署环境，TensorFlow 允许 client 简单地表达不同类型的并行通过复制和并行执行一个核心模型数据流图，依赖不同计算设备合作更新一个共享的参数或者其他的状态。 对计算描述的微妙变动可以使用较低的代价来达到和尝试很多不同的并行的方法。一些 TensorFlow 的用途借助参数更新的一致性来实现灵活性，我们可以在一些更大的部署环境中轻易表达和利用这些同步上的松弛。对比 DistBelief，TensorFlow 的编程模型更加灵活，性能也更好，支持在大规模的异构硬件平台上训练和使用很多的模型。</p>
<p>DistBelief 的内部用户已经切换成 TensorFlow 了。这些客户依赖 TensorFlow 来研究和产品，执行诸如在移动电话计算机视觉模型的推断到使用数百台机器进行千亿级样本的千亿级参数的深度神经网络的训练[11,47,48,18,53,41]。尽管这些应用集中在机器学习和深度神经网络上，我们希望 TensorFlow 的抽象可以用在其他的领域中，例如其他的机器学习算法或者可能其他类型的数值计算。我们按照 Apache 2.0 协议在 2015 年 11 月开源了 TensorFlow API，可以在 www.tensorflow.org 查看。</p>
<p>本文下面的部分更加细致地描述了 TensorFlow。第二节介绍编程模型和 TensorFlow 接口的基本概念，第三节介绍单机和分布式的实现 。第四节给出了基本编程模型的扩展，第五节介绍了一些基本实现的优化方法。第六节给出了一些使用 TensorFlow 的实验结果，第七节描述了一些使用 TensorFlow 编程的 idiom，第九节则是一些在 TensorFlow 核心外围的工具。第十节和第十一节分别讨论了未来和相关的工作，最后一节给出了总结性想法。</p>
<h1 id="2_编程模型和基本概念">2 编程模型和基本概念</h1><p>TensorFlow 的计算由一个有向图描述，这个图中由一个节点集合组成。该图表达了数据流计算，作出了一些类型的节点保持和更新持久状态和让分支及循环控制结构类似于 Naiad 的行为方式的扩展。客户一般都会使用 TensorFlow 支持的前端语言（C++或者Python）构建一个计算图。在图 1 中展示了一段样例使用 Python 构建并执行了一个 TensorFlow 的计算图，结构计算图在图 2 中展示。<br><img src="http://i.imgur.com/qpiRUIP.png" alt="图1"><br><img src="http://i.imgur.com/8FoQG55.png" alt="图2"></p>
<p>在一幅 TensorFlow 图中，每个节点（node）有一个或者多个输入和零个或者多个输出，表示一种操作（operation）的实例化。流过图中正常的边（输出到输入）的值都是张量（tensor），任意维度的数组其中基础元素类型是指定的或者在图的构造过程中自动推断出来的。特别的边，我们称之为控制依赖（control dependencies），同样也存在在图中：这类边上没有数据流过，但是他们表示源节点必须在目标节点的控制依赖开始执行前完成运行。因为我们的模型包括可变状态，控制依赖可以被直接用来强制在保证关系的发生。（Since our model includes mutable state, control dependencies can be used directly by clients to enforce happens before relationships.）我们的实现同样会插入控制依赖来确保独立操作之间的顺序，比如说作为控制内存使用最高峰值的方式。</p>
<h2 id="操作和核(Kernel)">操作和核(Kernel)</h2><p>一个操作有一个名字。它表示一个抽象的计算（比如说，“矩阵相乘”或者“相加”）。一个操作可以有属性（attribute），所有的属性必须提供或者在图构造的过程中推断出以实例化一个节点来执行操作。属性通常的使用方式是让操作在不同的张量元素类型上多态（例如，两个 float 类型的张量和两个 int32 类型的张量）。核（kernel）是一种操作的特别实现，可以运行在一个特定类型的设备上（如 CPU 或者 GPU）。TensorFlow 的 binary 定义了可以通过注册（registration）机制实现的操作和核的集合上，这个集合可以通过连接额外的操作/核的定义/注册。表 1 展示了内置于 TensorFlow 核心库的一些操作类型。<br><img src="http://i.imgur.com/VHx7CRW.png" alt="表1：TensorFlow的操作类型"></p>
<h2 id="会话(session)">会话(session)</h2><p>客户端通过创建会话（session）和 TensorFlow 系统进行交互。为了创建一个计算图，会话接口支持外部（external）方法来提升当前由包含额外节点和边的会话的图（当会话创建时初始的图是空的）。另一个由会话接口提供的主要的操作就是 Run，以需要计算的输出名称和替换某些输出节点的张量的操作集合作为其参数输入。通过控制 Run 的参数，TensorFlow 的实现可以计算所有节点的必须执行传递闭包来计算需要的输出，然后安排执行合适节点来保证他们的依赖关系（在3.1小节详细讲解）。大多数 TensorFlow 的使用都是针对一个图启动一个会话，然后执行整个图或者通过 Run 调用来执行分离的子图数千或者数百万次。</p>
<h2 id="变量(variable)">变量(variable)</h2><p>在大多数计算中，图都是执行多次的。大多数的张量在一次执行后不会存活。然而，变量（variable）是一种特别的操作可以返回一个在图执行若干次过程中存活的持久化的可变张量的句柄。这个句柄可以传递给一系列特定的操作，例如 Assign 和 AssignAdd（等同于 +=）就可以改变其引用的张量了。对应 TensorFlow 在机器学习中的应用，模型的参数典型地就存放在变量引用的张量中，并作为模型训练图的 Run 的一部分进行更新。</p>
<h1 id="3_实现">3 实现</h1><p>TensorFlow 系统的主要部分就是客户端，它使用了会话接口来和 master 及一个或者多个的 worker processes 进行通信，每个 worker process 负责对一个或者多个计算设备（CPU 核或者 GPU card）的任意访问和在这些设备上进行图节点的计算按照 master 的要求执行。我们有本地和分布式实现的 TensorFlow 接口。本地实现通常是客户端、master 和 worker 都是在同一台机器上在一个单一的操作系统进程（可能包括多个设备，比如说装了多个 GPU card的设备）上运行。分布式实现采用了本地实现的很多的代码，但是扩展了对客户端、master 和 worker 可以在不同的机器的不同的进程上运行的场景支持。在我们的分布式环境中，这些不同的任务对应于 cluster 调度系统分配在 job 中的容器中[51]。这两种不同的模式在图 3 中进行的展示。本节剩下的部分讨论了在两种实现中遇到的问题，3.3 节讨论了针对分布式实现的一些问题。</p>
<h2 id="设备">设备</h2><p>设备是 TensorFlow 的计算核心。每个 worker 负责一个或者多个设备，每个设备有一个设备类型和一个名字。设备名字由识别设备类型的部分，在 worker 中的设备索引，以及在分布式设定中，worker 的 job和任务（或者 localhost 当设备是和进程在同一机器时）的标志构成。一些例子如<code>/job:localhost/device:cpu:0</code> 或者 <code>/job:worker/task:17/device:gpu:3</code>。我们已实现了 CPU 和 GPU 的设备接口而其他的设备类型也有了通过注册机制完成的设备实现方式。每个设备对象负责管理分配和解除分配设备内存，对在 TensorFlow 实现中的更高层请求任意 kernel 的执行调度管理。</p>
<h2 id="张量">张量</h2><p>实现中的张量是一种有类型的、多维度数组。我们支持若干张量元素类型，包含大小为从 8 bit 到 64 bit 的带符号和无符号整型，IEEE 浮点数和双精度类型、复数类型和字符串类型（任意长的字节数组）。合适大小的后台存储通过一个分配器进行管理，该分配器由张量所处的设备确定。张量的后端存储缓存是引用计数的并在没有引用存在时解除分配。</p>
<h2 id="3-1_单设备执行">3.1 单设备执行</h2><p>首先考虑最简单的执行场景：单一的worker进程运行在单一的设备上。图上的节点按照代表节点之间的顺序执行。特别地，我们会在每个节点上保持一个计数来记录这个节点上还没有执行的依赖。一旦这个计数变为 0，节点就可以被调度使用，并会加入到待续的队列中。待续队列按照某个非指定的顺序处理，指派节点执行的kernel 到设备对象上。当一个节点完成执行，所有依赖这个完成的节点的节点的计数都会增加</p>
<h2 id="3-2_多设备执行">3.2 多设备执行</h2><p>一旦系统有了多个设备，有两个主要的复杂情形出现：确定图中每个节点的计算所处的设备，然后管理由上一步确定的置放决定产生的设备间的所需的数据通信。后续部分讨论这两个问题。</p>
<h3 id="3-2-1_节点的置放">3.2.1 节点的置放</h3><p>给定计算图，TensorFlow 实现的主要责任之一就是将计算映射到可用的设备集合上。这个算法的简单版本下面给出。参见第 4.3 节有关该算法支持的扩展。</p>
<p>该置放算法的输入是一个代价模型，包括对每个图节点的输入和输出张亮的规模的估计，和对每个节点在给于其输入张量时的计算时间的。这个代价模型或者是基于关联不同操作类型的启发式规则的静态估计，或者基于实际的为更早的图的执行而做的置放决定集合衡量。</p>
<p>置放算法首先运行模拟的图的执行过程。模拟按照下面描述进行，对每个节点使用贪心策略选择一个设备。节点到设备的置放过程也是用作真实执行的置放。</p>
<p>置放算法从计算图的源点开始，在系统中的每个设备上模拟相应的活动。对每个在遍历中抵达的节点，可选 available 设备的集合会被考虑到（设备可能会由于其没能提供实现了特定操作的kernel而不可选）。对那些拥有多个可选设备的节点，置放算法使用一种贪心策略来检查在每个可能谁被上置放节点需要完成的时间的效果完成决策。这种启发式规则考虑了根据代价模型在那种设备上估计的和衡量的执行时间，还有任何用来从其他设备传输输入到该节点的通信的代价。其中节点的操作完成最快的设备会被选作该操作的设备，置放决策然后会继续针对图中其他的节点进行处理，包含那些已经做好模拟执行的下游节点。第 4.3 节描述了一些扩展，让用户可以提供提示和部分限制来指导置放算法。这个算法现在还在持续开发的过程中。</p>
<h3 id="3-2-2_交叉设备通信">3.2.2 交叉设备通信</h3><p>一旦置放节点被计算，图会被分割成一系列的子图，每个子图在分布在1台设备上。任何从x到y的交叉设备的边会被移除，然后被一个从x到新的发送节点的边代替</p>
<h2 id="3-3_分布式执行">3.3 分布式执行</h2><h1 id="4_扩展">4 扩展</h1><h2 id="4-1_梯度计算">4.1 梯度计算</h2><h2 id="4-2_部分执行">4.2 部分执行</h2><h2 id="4-3_设备限制">4.3 设备限制</h2><h2 id="4-4_控制流">4.4 控制流</h2><h2 id="4-5_输入操作">4.5 输入操作</h2><h2 id="4-6_队列">4.6 队列</h2><h2 id="4-7_容器">4.7 容器</h2><h1 id="5_优化">5 优化</h1><h2 id="5-1_通常子表达式消除">5.1 通常子表达式消除</h2><h2 id="5-2_控制数据通信和内存分配">5.2 控制数据通信和内存分配</h2><h2 id="5-3_异步Kernel">5.3 异步Kernel</h2><h2 id="5-4_用于Kernel实现的优化库">5.4 用于Kernel实现的优化库</h2><h2 id="5-5_有损压缩">5.5 有损压缩</h2><h1 id="6_状态和经验">6 状态和经验</h1><h1 id="7_常用编程规范">7 常用编程规范</h1><h1 id="8_性能">8 性能</h1><h1 id="9_工具">9 工具</h1><h2 id="9-1_TensorBoard:图结构和总结统计可视化">9.1 TensorBoard:图结构和总结统计可视化</h2><h2 id="9-2_性能追踪">9.2 性能追踪</h2><h1 id="10_未来工作">10 未来工作</h1><h1 id="11_相关工作">11 相关工作</h1><h1 id="12_结论">12 结论</h1><h1 id="参考文献">参考文献</h1>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="TensorFlow:大规模机器学习的异构分布式系统">TensorFlow:大规模机器学习的异构分布式系统</h1><blockquote>
<p>TensorFlow从名称上看就是两个部分——张量tensor和流flow。非常形象的组合。众所周知，矩阵已经成为]]>
    </summary>
    
      <category term="Machine learning" scheme="http://yoursite.com/tags/Machine-learning/"/>
    
      <category term="TensorFLow" scheme="http://yoursite.com/tags/TensorFLow/"/>
    
      <category term="TensorFLow" scheme="http://yoursite.com/categories/TensorFLow/"/>
    
      <category term="Machine learning" scheme="http://yoursite.com/categories/TensorFLow/Machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[TensorFlow示例程序]]></title>
    <link href="http://yoursite.com/2015/11/23/TensorFlowInstall/"/>
    <id>http://yoursite.com/2015/11/23/TensorFlowInstall/</id>
    <published>2015-11-23T09:40:20.000Z</published>
    <updated>2015-11-23T12:54:31.825Z</updated>
    <content type="html"><![CDATA[<h1 id="第一个TensorFLow程序">第一个TensorFLow程序</h1><pre><code><span class="variable">$python</span>
&gt;&gt;&gt;import tensorflow as tf
&gt;&gt;&gt;hello=tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="string">'Hello, TensorFlow!'</span>)</span></span>
&gt;&gt;&gt;sess=tf.<span class="function"><span class="title">Session</span><span class="params">()</span></span>
&gt;&gt;&gt;print sess.<span class="function"><span class="title">run</span><span class="params">(hello)</span></span>
Hello, TensorFlow!
&gt;&gt;&gt;a=tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="number">10</span>)</span></span>
&gt;&gt;&gt;b=tf.<span class="function"><span class="title">constant</span><span class="params">(<span class="number">32</span>)</span></span>
&gt;&gt;&gt;print sess.<span class="function"><span class="title">run</span><span class="params">(a+b)</span></span>
 <span class="number">42</span>
&gt;&gt;&gt;
</code></pre><h1 id="第二个TensorFlow程序">第二个TensorFlow程序</h1><pre><code> import tensorflow <span class="keyword">as</span> tf
import numpy <span class="keyword">as</span> np
<span class="comment">#Make 100 phony data points in NumPy</span>
x_data=np.float32(np.random.rand(<span class="number">2</span>,<span class="number">100</span>))<span class="comment">#Random input</span>
y_data=np.dot([<span class="number">0.100</span>,<span class="number">0.200</span>], x_data)+<span class="number">0.300</span>

 <span class="comment">#Construct a linear model</span>
 b=tf.Variable(tf.zeros([<span class="number">1</span>])
 W=tf.Variable(tf.random_uniform([<span class="number">1</span>,<span class="number">2</span>],-<span class="number">1.0</span>,<span class="number">1.0</span>))
 y=tf.matmul(W,x_data)+b
<span class="comment">#Minimize the squared errors</span>
loss=tf.reduce_mean(tf.square(y-y_data))
optimizer=tf.train.GradientDescentOptimizer(<span class="number">0.5</span>)
 train=optimizer.minimize(loss)

<span class="comment">#For initializing the variables.</span>
 init=tf.initialize_all_variables()

 <span class="comment">#Launch the graph</span>
sess=tf.Session()
 sess.<span class="command">run</span>(init)

 <span class="comment">#Fit the plane</span>
<span class="keyword">for</span> step <span class="keyword">in</span> xrange(<span class="number">0</span>,<span class="number">201</span>):
     sess.<span class="command">run</span>(train)
     <span class="keyword">if</span> step%<span class="number">20</span>==<span class="number">0</span>:
         print step,sess.<span class="command">run</span>(W),sess.<span class="command">run</span>(b)<span class="comment">#这里一定要记得缩进，否则会报错</span>

 <span class="comment">#Learns best fit is W:[[0.100 0.200]],b: [0.300]</span>
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="第一个TensorFLow程序">第一个TensorFLow程序</h1><pre><code><span class="variable">$python</span>
&gt;&gt;&gt;import tensorflow as tf
&gt;&gt;&g]]>
    </summary>
    
      <category term="Machine learning" scheme="http://yoursite.com/tags/Machine-learning/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/tags/TensorFlow/"/>
    
      <category term="TensorFlow" scheme="http://yoursite.com/categories/TensorFlow/"/>
    
      <category term="Machine learning" scheme="http://yoursite.com/categories/TensorFlow/Machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[百度世界2015，“度秘”(Duer)讲了一则怎样的故事]]></title>
    <link href="http://yoursite.com/2015/11/10/01-info/"/>
    <id>http://yoursite.com/2015/11/10/01-info/</id>
    <published>2015-11-10T09:21:56.000Z</published>
    <updated>2015-11-10T13:11:13.359Z</updated>
    <content type="html"><![CDATA[<p>文章转载自：<a href="http://www.huxiu.com/article/125411/1.html" target="_blank" rel="external">百度世界2015，“度秘”讲了一则怎样的故事</a></p>
<p><img src="http://i.imgur.com/6oraXok.png" alt=""><br>阿兰·图灵认为，如果一台机器能够与人类展开对话而不能被辨别其机器身份，那么它就抵达了可被称为人工智能的境地。</p>
<p>有趣的是，以1991年为始，不断有人宣称某款聊天机器人“史上首次”通过图灵测试，由于人类样本缺少标准，多数用于挑战的机器人程序都力求“伶牙俐齿”，注以讽刺、反问、厌倦等情绪语句试图蒙蔽人类对象。</p>
<p>一言蔽之，我们对于“人性”的要求，或许与阿兰·图灵在六十多年前的设计初衷早已分道扬镳：人工智能的优劣，在于它能否取悦规则，而非伦理或是哲学层面的突破。</p>
<p>故而微软小冰的卖萌战术能够横扫中文社交网络，调戏Siri也成为了风靡世界的某种恶趣味。不是恐怖的拥有自我学习能力的机器人在挑战位于智慧种族顶端的人类，而是愚蠢不堪的人类在绞尽脑汁的挑战机器人、试图难倒后者或是使其“出尽洋相”。</p>
<p>娱乐至上始终是主旋律，就像当今智能手机的计算能力早已远超美国发射阿波罗11号探月的大型计算机，但是人们仍然只会摩擦屏幕玩着《愤怒的小鸟》。然而，这并不妨碍科技企业抢占未来机遇的决心，人工智能的性质意味着它作为解决方案具有高度的统筹能力，不可替代性极高。</p>
<p>在美国，语义分析、深度学习等领域的专家早被瓜分一空，苹果、Google、亚马逊和微软，纷纷开始尝试说服本土高校的教授们放弃终身制的教职加入商业公司，它们同时还要提防学习能力过强的中国竞敌横刀夺爱，当Google失去了吴恩达、微软失去了张亚勤之后，接盘者的受益效果很快显现：“BAT”之中，百度第一个拿出了完成度极高的机器人助理产品“度秘”。</p>
<p>“度秘”亮相于百度年度最高规格的活动“百度世界”，李彦宏将其使命描述为“索引真实世界”，一语道出百度对于人工智能的定义：它不应当是一个排解无聊、逗人捧腹的玩物，而是一款具备主动计算能力、接管用户生活需求的工具。</p>
<p>包括李彦宏在内，百度负责技术的几名高管，都将发言重点聚焦于“度秘”的技术天赋以及解决问题的简洁路径，“百度提供的秘书”这一命名的国情特色相当突出，所谓“秘书”，符合的其实是召之即来挥之即去、能办事儿却不多话的岗位想象。</p>
<p>如果说“我是谁、我从哪里来、我到何处去”是哲学经验的三大终极问题，用于商业化的人工智能产品同样需要回答这三个问题：“我是谁”意指身份认同问题和能力边界问题；“我从哪里来”意指数据来源问题，处于计算的底层；而“我到何处去”意指用户服务问题，处于计算的前端。</p>
<p><img src="http://i.imgur.com/koU8nN9.png" alt=""></p>
<p>这是2014年百度技术开放日揭晓的“百度大脑”项目的运作原理图解，它与李彦宏在今年百度世界上解说“度秘”时划分的三个层级——底层连接3600行、中层全网数据挖掘、上层理解用户需求——是一脉相承的：</p>
<p>首先要解决的，是突破App的孤岛效应而获取数据。当超链接文本协议在移动端全面失效，通过爬虫进行索引收录的方式也就变得遥不可求，所以“连接能力”进而显得至关重要，即应用方需要主动加入进来贡献数据，而实现这一诉求的前提，是要取得应用方的信赖和足够分而食之的利益。</p>
<p>其次要解决的，是有了数据之后，怎样处理这些数据。“大数据”的概念虽火，但是数据规模越大，冗余存量也就越多，缺少提炼能力，这些数据就只会消耗储存空间。吴恩达在Google时曾使深度学习系统能够识别猫的图片，这在当时成为一件震惊业界的新闻。吴恩达在百度继续的神经网络技术，目的也是驱动技术的变革，将数据的获取途径进一步延伸到各类传感器上。</p>
<p>最后剩下的，就是与用户发生沟通，接受市场的检验。百度曾被质疑移动战略杂乱无章，但是随着时间推移，所有的布局都被连成了一条线，即手机百度（入口端）、百度糯米（交易端）、百度地图（本地端）三点一线，“度秘”最为技术支持，成为撑起所有服务的一根支柱。</p>
<p>李彦宏与比尔·盖茨私交甚好，他们或许属于同一类极客——后者创办微软之前，曾经毫不客气的批评另一群主张破解与共享的极客“使用软件需要付钱”——信奉技术的力量，并追求将之发扬实现回报。</p>
<p>因此，相比Siri和Google Now，“度秘”的实用主义色彩十分显眼，它的舞台在其诞生之前就已搭好，货币化的前程亦可预期，这种取舍，让人想起李彦宏的早年经历：他在松下信息技术研究所实习时就已在涉足人工智能的识别效率课题，而工业研究解决实际问题的特点使李彦宏放弃校园研究以及博士学位，转投道琼斯旗下开发搜索技术。</p>
<p>换句话说，在李彦宏看来，不能被商业市场接纳的技术产品，都有违他的职业价值观。这种坚持，亦影响了百度的团队作风，比如还是吴恩达，他在Google用面部识别技术学会了认猫，在百度则是开发出了名为“脸优”的换脸App，上架iOS试图冲击“爆款”。</p>
]]></content>
    <summary type="html">
    <![CDATA[<p>文章转载自：<a href="http://www.huxiu.com/article/125411/1.html" target="_blank" rel="external">百度世界2015，“度秘”讲了一则怎样的故事</a></p>
<p><img src="htt]]>
    </summary>
    
      <category term="IT互联网那些事" scheme="http://yoursite.com/tags/IT%E4%BA%92%E8%81%94%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    
      <category term="IT互联网那些事" scheme="http://yoursite.com/categories/IT%E4%BA%92%E8%81%94%E7%BD%91%E9%82%A3%E4%BA%9B%E4%BA%8B/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[排序算法汇总]]></title>
    <link href="http://yoursite.com/2015/10/15/sorting/"/>
    <id>http://yoursite.com/2015/10/15/sorting/</id>
    <published>2015-10-15T14:05:44.000Z</published>
    <updated>2015-10-24T12:10:56.110Z</updated>
    <content type="html"><![CDATA[<h1 id="排序综述">排序综述</h1><p><img src="http://i.imgur.com/0mmOczf.png" alt=""></p>
<h2 id="概念">概念</h2><p>假设含有n个记录的序列为<code>{r1,r2,r3,...,rn}</code>，其关键字分别为<code>{k1,k2,k3,...,kn}</code>，需确定<code>1,2,...,n</code>的一种排列<code>p1,p2,...,pn</code>，使其关键字满足<code>kp1&lt;=kp2&lt;=...&lt;=kpn</code>非递减（或非递增）关系，即使得序列成为一个按关键字有序的序列，这样的操作叫排序。</p>
<h2 id="内排序和外排序">内排序和外排序</h2><p>1、内排序是在排序整个过程中，待排序的所有记录全部放置在内存中；<br>2、外排序是由于排序的记录个数太多，不能同时放置在内存，整个排序过程需要在内外村之间多次交换才能进行。</p>
<p>这里只讨论内排序。</p>
<h2 id="排序算法的性能">排序算法的性能</h2><p><strong>1、时间性能</strong><br>排序算法的时间开销是衡量其好坏的最重要指标。在内排序中，主要进行两种操作：<code>比较和移动</code>。</p>
<p>高效率的内排序算法应该是具有尽可能少的关键字比较次数和尽可能少的记录移动次数。</p>
<p><strong>2、辅助空间</strong><br>辅助空间是除了存放待排序数据所占用的存储空间之外，执行算法所需要的其他存储空间。</p>
<p><strong>3、内排序算法总览</strong></p>
<h2 id="交换排序">交换排序</h2><h3 id="冒泡排序">冒泡排序</h3><pre><code><span class="comment">/*交换x,y*/</span>
<span class="function"><span class="keyword">void</span> <span class="title">swap</span><span class="params">(<span class="keyword">int</span> *x,<span class="keyword">int</span> *y)</span>
</span>{
    <span class="keyword">int</span> temp;
    temp=*x;
    *x=*y;
    *y=temp;
}
<span class="comment">/*交换排序之冒泡排序*/</span>
<span class="function"><span class="keyword">void</span> <span class="title">BubbleSort</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> length)</span>
</span>{
    <span class="keyword">int</span> i,j;
    <span class="keyword">bool</span> flag=<span class="literal">true</span>;<span class="comment">//用于标记是否交换，如果没有交换直接跳过 </span>
    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;length&amp;&amp;flag;i++){
        flag=<span class="literal">false</span>;
        <span class="keyword">for</span>(j=length-<span class="number">2</span>;j&gt;=i;j--){
            <span class="keyword">if</span>(a[j]&gt;a[j+<span class="number">1</span>]){
                swap(&amp;a[j],&amp;a[j+<span class="number">1</span>]);
                flag=<span class="literal">true</span>;
            }
        }
    }
}
</code></pre><h3 id="快速排序">快速排序</h3><pre><code><span class="function"><span class="keyword">int</span> <span class="title">Patition</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> low,<span class="keyword">int</span> high)</span>
</span>{
    <span class="keyword">int</span> pivotkey=a[low];
    <span class="keyword">while</span>(low&lt;high){
        <span class="keyword">while</span>(low&lt;high&amp;&amp;a[high]&gt;pivotkey)
            --high;
        swap(&amp;a[high],&amp;a[high]);
        <span class="keyword">while</span>(low&lt;high&amp;&amp;a[low]&lt;pivotkey)
            ++low;
        swap(&amp;a[low],&amp;a[high]);
    }
    <span class="keyword">return</span> low;
}
<span class="function"><span class="keyword">void</span> <span class="title">Qsort</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> low,<span class="keyword">int</span> high)</span>
</span>{
    <span class="keyword">int</span> pivot;
    <span class="keyword">if</span>(low&lt;high){
        pivot=Patition(a,low,high);
        Qsort(a,low,pivot-<span class="number">1</span>);
        Qsort(a,pivot+<span class="number">1</span>,high);
    }
}
</code></pre><h2 id="选择排序">选择排序</h2><h3 id="简单选择排序">简单选择排序</h3><pre><code><span class="keyword">void</span> SelectSort(<span class="keyword">int</span> a[],<span class="keyword">int</span> <span class="built_in">length</span>)
{
    <span class="keyword">int</span> i,j,<span class="built_in">min</span>;
    <span class="keyword">for</span>(i=<span class="number">0</span>;i&lt;<span class="built_in">length</span>;i++){
        <span class="built_in">min</span>=i;
        <span class="keyword">for</span>(j=i+<span class="number">1</span>;j&lt;<span class="built_in">length</span>;j++){
            <span class="keyword">if</span>(a[<span class="built_in">min</span>]&gt;a[j])
                <span class="built_in">min</span>=j;
        }
        <span class="keyword">if</span>(i!=<span class="built_in">min</span>)
            swap(&amp;a[i],&amp;a[<span class="built_in">min</span>]);    
    }
}
</code></pre><h3 id="堆排序">堆排序</h3><pre><code><span class="function"><span class="keyword">void</span> <span class="title">HeapDown</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> s,<span class="keyword">int</span> m)</span>
</span>{
    <span class="keyword">int</span> i,temp;
    temp=a[s];
    <span class="keyword">for</span>(i=s*<span class="number">2</span>;i&lt;=m;i*=<span class="number">2</span>){
        <span class="keyword">if</span>(i&lt;m&amp;&amp;a[i]&lt;a[i+<span class="number">1</span>])
            ++i;
        <span class="keyword">if</span>(temp&gt;=a[i])
            <span class="keyword">break</span>;
        a[s]=a[i];
        s=i;
    }
    a[s]=temp;
}
<span class="function"><span class="keyword">void</span> <span class="title">HeapSort</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> length)</span>
</span>{
    <span class="keyword">int</span> i,j;
    <span class="keyword">for</span>(i=length/<span class="number">2</span>;i&gt;=<span class="number">0</span>;i--)
        HeapDown(a,i,length-<span class="number">1</span>);
    <span class="keyword">for</span>(j=length-<span class="number">1</span>;j&gt;<span class="number">0</span>;j--)
    {
        swap(&amp;a[<span class="number">0</span>],&amp;a[j]);
        HeapDown(a,<span class="number">0</span>,j-<span class="number">1</span>);    
    }
}
</code></pre><h2 id="插入排序">插入排序</h2><h3 id="直接插入排序">直接插入排序</h3><pre><code>void InsertSort(int a[],int length)
<span class="comment">{
    int i,j,temp;
    for(i=1;i&lt;length;i++){
        if(a[i]&lt;a[i-1]){
            temp=a[i];
            for(j=i-1;j&gt;=0&amp;&amp;a[j]&gt;temp;j--)
                a[j+1]=a[j];
            a[j+1]=temp;
        }</span>
    }
}
</code></pre><h3 id="希尔排序">希尔排序</h3><h2 id="归并排序">归并排序</h2><pre><code><span class="function"><span class="keyword">void</span> <span class="title">Merge</span><span class="params">(<span class="keyword">int</span> S[],<span class="keyword">int</span> T[],<span class="keyword">int</span> s,<span class="keyword">int</span> m,<span class="keyword">int</span> t)</span>
</span>{
    <span class="keyword">int</span> j,k,l;
    <span class="keyword">for</span>(j=m+<span class="number">1</span>,k=s;s&lt;=m&amp;&amp;j&lt;=t;k++){
        <span class="keyword">if</span>(S[s]&lt;S[j])
            T[k]=S[s++];
        <span class="keyword">else</span>
            T[k]=S[j++];
    }
    <span class="keyword">if</span>(s&lt;=m){
        <span class="keyword">for</span>(l=<span class="number">0</span>;l&lt;=m-s;l++)
            T[k+l]=S[s+l];
    }
    <span class="keyword">if</span>(j&lt;=t){
        <span class="keyword">for</span>(l=<span class="number">0</span>;l&lt;=t-j;l++)
            T[k+l]=S[j+l];
    }
}
<span class="function"><span class="keyword">void</span> <span class="title">MSort</span><span class="params">(<span class="keyword">int</span> S[],<span class="keyword">int</span> T1[],<span class="keyword">int</span> s,<span class="keyword">int</span> t)</span>
</span>{
    <span class="keyword">int</span> m;
    <span class="keyword">int</span> T2[<span class="number">200</span>];
    <span class="keyword">if</span>(s==t)
        T1[s]=S[s];
    <span class="keyword">else</span>{
        m=(s+t)/<span class="number">2</span>;
        MSort(S,T2,s,m);
        MSort(S,T2,m+<span class="number">1</span>,t);
        Merge(T2,T1,s,m,t);
    }
}
<span class="function"><span class="keyword">void</span> <span class="title">MergeSort</span><span class="params">(<span class="keyword">int</span> a[],<span class="keyword">int</span> length)</span>
</span>{
    MSort(a,a,<span class="number">0</span>,length-<span class="number">1</span>);
} 
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="排序综述">排序综述</h1><p><img src="http://i.imgur.com/0mmOczf.png" alt=""></p>
<h2 id="概念">概念</h2><p>假设含有n个记录的序列为<code>{r1,r2,r3,...,rn}</c]]>
    </summary>
    
      <category term="Data Structure&amp;Algorithm" scheme="http://yoursite.com/tags/Data-Structure-Algorithm/"/>
    
      <category term="Sorting" scheme="http://yoursite.com/tags/Sorting/"/>
    
      <category term="Algorithm basic" scheme="http://yoursite.com/categories/Algorithm-basic/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Standord Machine Learning notes-week5]]></title>
    <link href="http://yoursite.com/2015/10/11/ML-standord-week5/"/>
    <id>http://yoursite.com/2015/10/11/ML-standord-week5/</id>
    <published>2015-10-11T08:02:09.000Z</published>
    <updated>2015-10-11T09:13:14.803Z</updated>
    <content type="html"><![CDATA[<h1 id="Neural_Networks:Learning（神经网络：学习）">Neural Networks:Learning（神经网络：学习）</h1><h2 id="Cost_function（代价函数）">Cost function（代价函数）</h2><p>神经网络是最强大的学习算法之一，这周和以下几周课程将会讲述在给定训练集下，为神经网络拟合参数的学习算法。现在从讨论神经网络的代价函数开始讲起。</p>
<h3 id="神经网络（分类）">神经网络（分类）</h3><p><img src="http://i.imgur.com/irWMLwG.png" alt=""><br>如图所示，假设存在这样一个神经网络，有m个训练样本<code>（x(i),y(i))</code>，<code>L</code>表示这个神经网络结构的总层数。<code>sl</code>第l层的神经元的数量，这其中不包括L层的<code>bias</code>。</p>
<p>现在讨论两种分类问题：（1）y只能取0或1，只有1类，1个输出单元；（2）多类别的分类问题，有K个输出（K&gt;=3)。<br><img src="http://i.imgur.com/wTsMq3u.png" alt=""></p>
<p>第一行是逻辑回归的代价函数，这里并没有把偏差项<code>theta0</code>正则化。对于神经网络，我们的代价函数是这个式子的一般化形式。这里不仅只有一个逻辑回归输出单元，取而代之的是K个，h(x)是一个K维向量，<code>i</code>表示选择了神经网络的第i个元素。对k从1到K进行了求和，这是对K个输出单元的求和。代价函数的第二项是正则化项。这里要做的就是把所有theta(ji)的值都相加。这里要除去那些对应于偏差值的项，对于i=0的项要加入其中，当我们计算神经元的激励值时，所有下标i=0的项（Bias）都要加入到正则化项里，因为我们不想正则化这些项，并把这些项设为0。但这只是我们合理的假设，如果i从0加到sl，也依然成立，并且不会有太大差异，但是如果不把偏差项正则化可能更常见一些。</p>
<h2 id="Backpropagation_algorithm（反向传播）">Backpropagation algorithm（反向传播）</h2><p>让代价函数最小化的算法——反向传播算法。<br><img src="http://i.imgur.com/oHYNoZe.png" alt=""><br>为了能使用梯度下降或者其他高级的算法，我们需要做的就是写好一个可以通过输入一个参数<code>theta</code>，然后计算<code>J(theta）</code>和对应的偏导项。这节主要讲如何计算偏导项。</p>
<h3 id="Gradient_computation（梯度计算）">Gradient computation（梯度计算）</h3><p>从只有一个训练样本（x,y)说起。<br>首先由前向传播，计算一下在给定输入的时候，假设函数是否会真的输出结果。</p>
<p><img src="http://i.imgur.com/XHiMOPg.png" alt=""></p>
<p>具体来说，<code>a(1)</code>就是第一层的激励值，也就是输入层；<code>a(2)是隐藏层的激励值</code>，<code>g</code>是sigmoid函数。这里实现了把前向传播向量化，从而可以计算每一层神经元的激励值。</p>
<p>接下来为了计算偏导项，引入一种叫做<code>反向传播（backpropagation）算法</code>。</p>
<h3 id="Gradient_computation（梯度计算）：反向传播算法">Gradient computation（梯度计算）：反向传播算法</h3><p>反向传播算法从直观上说，就是对每个结点，我们计算这样一项<code>thetaj(l)</code>，代表第l层的第i个结点的误差。这项捕捉了在这个神经结点的激励值的误差。<br><img src="http://i.imgur.com/flNStUJ.png" alt=""><br>具体来说，右边这个有四层的神经网络结构做例子。要计算<code>delta(4)</code>就要先计算<code>delta(3)</code>和<code>delta(2)</code>。<code>g&#39;(z(3)</code>实际上是在输入值为z(3)的时候所求的导数。</p>
<p>这里没有<code>delta(1)</code>，因为第一层对应输入层，那只是表示我们在训练集观察到的，所以不会存在误差。那么这个例子中的误差只有第二层和第三层。</p>
<p>反向传播这个名字源于我们从输入层开始计算delta项，然后我们返回上一层计算第三层隐藏层的delta，然后不断反向计算。所以，我们是类似于把输入层的误差反向传播给第三层，第二层。</p>
<p>最后通过复杂的数学推导，我们可以得到J(theta)的偏导数项（PPT最后一行）。</p>
<p>如果有多个训练样本：</p>
<p>先初始化，然后便利所有训练样本。对于第一个循环，我们取训练样本(x(i),y(i))，取a(1)=x(1),也就是输入层的激励函数，</p>
]]></content>
    <summary type="html">
    <![CDATA[<h1 id="Neural_Networks:Learning（神经网络：学习）">Neural Networks:Learning（神经网络：学习）</h1><h2 id="Cost_function（代价函数）">Cost function（代价函数）</h2><p>神经网]]>
    </summary>
    
      <category term="Machine learning" scheme="http://yoursite.com/tags/Machine-learning/"/>
    
      <category term="Machine learning笔记" scheme="http://yoursite.com/tags/Machine-learning%E7%AC%94%E8%AE%B0/"/>
    
      <category term="Machine learning" scheme="http://yoursite.com/categories/Machine-learning/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[Matlab command汇总]]></title>
    <link href="http://yoursite.com/2015/09/29/matlab-command/"/>
    <id>http://yoursite.com/2015/09/29/matlab-command/</id>
    <published>2015-09-29T07:11:16.000Z</published>
    <updated>2015-09-29T13:46:46.082Z</updated>
    <content type="html"><![CDATA[<h1 id="Basic_Operations">Basic Operations</h1><h2 id="算术运算">算术运算</h2><pre><code><span class="prompt">&gt;&gt;</span><span class="number">1</span>+<span class="number">2</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">3</span>

<span class="prompt">&gt;&gt;</span><span class="number">10</span>-<span class="number">7</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">3</span>

<span class="prompt">&gt;&gt;</span><span class="number">2</span>*<span class="number">10</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">20</span>

<span class="prompt">&gt;&gt;</span><span class="number">1</span>/<span class="number">2</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">0</span>.<span class="number">50000</span>

<span class="prompt">&gt;&gt;</span><span class="number">2</span>^<span class="number">6</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">64</span>
</code></pre><h2 id="逻辑运算">逻辑运算</h2><pre><code><span class="prompt">&gt;&gt;</span><span class="number">1</span> == <span class="number">2</span> %comparison
<span class="prompt">&gt;&gt;</span>ans=<span class="number">0</span>

<span class="prompt">&gt;&gt;</span><span class="number">1</span> ~= <span class="number">2</span> %not equal
<span class="prompt">&gt;&gt;</span>ans=<span class="number">1</span>

<span class="prompt">&gt;&gt;</span><span class="number">1</span> &amp;&amp; <span class="number">0</span> %<span class="constant">AND</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">0</span>

<span class="prompt">&gt;&gt;</span><span class="number">1</span> || <span class="number">0</span> %<span class="constant">OR</span>
<span class="prompt">&gt;&gt;</span>ans=<span class="number">1</span>

<span class="prompt">&gt;&gt;</span>xor(<span class="number">1</span>,<span class="number">0</span>)
<span class="prompt">&gt;&gt;</span>ans=<span class="number">1</span>
</code></pre><h2 id="变量">变量</h2><h3 id="变量赋值">变量赋值</h3><pre><code><span class="prompt">&gt;&gt;</span>a=<span class="number">3</span>; %加上“；”表示不打印结果
<span class="prompt">&gt;&gt;</span>b=<span class="string">'hi'</span>
<span class="prompt">&gt;&gt;</span>c= (<span class="number">3</span>&gt;=<span class="number">1</span>)
c=<span class="number">1</span>
</code></pre><h3 id="显示变量">显示变量</h3><pre><code>&gt;&gt;<span class="literal">a</span>=pi<span class="comment">;</span>
&gt;&gt;<span class="literal">a</span>
<span class="literal">a</span>=<span class="number">3.1416</span>
&gt;&gt;disp(<span class="literal">a</span>)<span class="comment">;</span>
<span class="number">3.1416</span>
</code></pre><h3 id="保留小数点后两位输出">保留小数点后两位输出</h3><pre><code>&gt;&gt;<span class="function"><span class="title">disp</span><span class="params">(sprintf(<span class="string">'2 decimals: %0.2f'</span>,a)</span></span>)
<span class="number">2</span> decimals: <span class="number">3.14</span>
</code></pre><h3 id="高精度&amp;低精度输出">高精度&amp;低精度输出</h3><pre><code><span class="prompt">&gt;&gt;</span>a=<span class="number">3.1416</span>
<span class="prompt">&gt;&gt;</span>format long
<span class="prompt">&gt;&gt;</span>a
a=<span class="number">3.14159265358979</span>
<span class="prompt">&gt;&gt;</span>format short
<span class="prompt">&gt;&gt;</span>a
a=<span class="number">3.1416</span>
</code></pre><h3 id="向量与矩阵（Vector_and_Matrix）">向量与矩阵（Vector and Matrix）</h3><h4 id="矩阵表示">矩阵表示</h4><pre><code>&gt;&gt;A=[<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]  %A是一个<span class="number">2</span>*<span class="number">3</span>的矩阵，分号表示另起一行
A=
    <span class="number">1</span> <span class="number">2</span>
    <span class="number">3</span> <span class="number">4</span>
    <span class="number">5</span> <span class="number">6</span>
</code></pre><h4 id="向量表示">向量表示</h4><pre><code>&gt;&gt;v=[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span>]   %v是一个<span class="number">1</span>*<span class="number">3</span>的矩阵或者说是行向量
v=
    <span class="number">1</span> <span class="number">2</span> <span class="number">3</span>
&gt;&gt;v=[<span class="number">1</span>;<span class="number">2</span>;<span class="number">3</span>]   %v是一个<span class="number">3</span>*<span class="number">1</span>的矩阵或者说是列向量
</code></pre><h4 id="在[m,n]范围内以固定步长生成元素">在[m,n]范围内以固定步长生成元素</h4><pre><code>&gt;&gt;v=<span class="number">1</span>:<span class="number">0.1</span>:<span class="number">2</span>   %以<span class="number">0.1</span>的步长生成范围在<span class="number">1</span>~<span class="number">2</span>之间的元素
&gt;&gt;v=<span class="number">1</span>:<span class="number">6</span>       %默认以<span class="number">1</span>为步长
</code></pre><h4 id="取矩阵的整行或整列">取矩阵的整行或整列</h4><pre><code>&gt;&gt;A(<span class="number">2</span>,:) %取A的第二行所有元素
&gt;&gt;A<span class="comment">(:,2) %取A的第二列所有元素
&gt;&gt;A([1 3],:)</span>  %取A得第一行和第三行所有元素
</code></pre><h4 id="矩阵赋值">矩阵赋值</h4><pre><code>&gt;&gt;A=[<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]
A=
    <span class="number">1</span> <span class="number">2</span>
    <span class="number">3</span> <span class="number">4</span>
    <span class="number">5</span> <span class="number">6</span>
&gt;&gt;A(:<span class="number">2</span>)=[<span class="number">10</span>;<span class="number">11</span>;<span class="number">12</span>]  %把列向量[<span class="number">10</span>;<span class="number">11</span>;<span class="number">12</span>]赋给A的第二列
A=
    <span class="number">1</span> <span class="number">10</span>
    <span class="number">3</span> <span class="number">11</span>
    <span class="number">5</span> <span class="number">12</span>
</code></pre><h4 id="给矩阵增一列">给矩阵增一列</h4><pre><code>&gt;&gt;A=[A, [<span class="number">100</span>;<span class="number">101</span>;<span class="number">102</span>]
A=
    <span class="number">1</span> <span class="number">10</span> <span class="number">100</span>
    <span class="number">3</span> <span class="number">11</span> <span class="number">101</span>
    <span class="number">5</span> <span class="number">12</span> <span class="number">102</span>
</code></pre><h4 id="把A中所有元素放入一个列向量">把A中所有元素放入一个列向量</h4><pre><code>&gt;&gt;A(:)
ans=
    <span class="number">1</span>
    <span class="number">3</span>
    <span class="number">5</span>
    <span class="number">10</span>
    <span class="number">11</span>
    <span class="number">12</span>
    <span class="number">100</span>
    <span class="number">101</span>
    <span class="number">102</span>
</code></pre><h4 id="合并矩阵">合并矩阵</h4><pre><code>&gt;&gt;A=[<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]
A=
    <span class="number">1</span> <span class="number">2</span>
    <span class="number">3</span> <span class="number">4</span>
    <span class="number">5</span> <span class="number">6</span>
&gt;&gt;B=[<span class="number">11</span> <span class="number">12</span>;<span class="number">13</span> <span class="number">14</span>;<span class="number">15</span> <span class="number">16</span>]
B=
    <span class="number">11</span> <span class="number">12</span>
    <span class="number">13</span> <span class="number">14</span>
    <span class="number">15</span> <span class="number">16</span>
&gt;&gt;C=[A B]
C=
    <span class="number">1</span> <span class="number">2</span> <span class="number">11</span> <span class="number">12</span>
    <span class="number">3</span> <span class="number">4</span> <span class="number">13</span> <span class="number">14</span>
    <span class="number">5</span> <span class="number">6</span> <span class="number">15</span> <span class="number">16</span>

&gt;&gt;C=[A;B]  %分号表示把B放到A下面
C=
    <span class="number">1</span> <span class="number">2</span>
    <span class="number">3</span> <span class="number">4</span>
    <span class="number">5</span> <span class="number">6</span>
    <span class="number">11</span> <span class="number">12</span>
    <span class="number">13</span> <span class="number">14</span>
    <span class="number">15</span> <span class="number">16</span>
</code></pre><h4 id="生成全0或全1矩阵">生成全0或全1矩阵</h4><pre><code>&gt;&gt;ones(<span class="number">2</span>,<span class="number">3</span>)
ans=
    <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>
    <span class="number">1</span> <span class="number">1</span> <span class="number">1</span>    
&gt;&gt;zeros(<span class="number">2</span>,<span class="number">3</span>)
ans=
    <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>
    <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>
</code></pre><h4 id="生成随机矩阵">生成随机矩阵</h4><pre><code>&gt;&gt;rand(<span class="number">3</span>,<span class="number">3</span>)   %生成<span class="number">3</span>*<span class="number">3</span>的矩阵，矩阵里所有元素值介于[<span class="number">0</span>,<span class="number">1</span>]
&gt;&gt;rands(<span class="number">3</span>,<span class="number">3</span>)  %生成<span class="number">3</span>*<span class="number">3</span>的矩阵，矩阵的所有元素符合均值为<span class="number">0</span>，标准差为<span class="number">1</span>的高斯分布
</code></pre><h4 id="绘制向量直方图">绘制向量直方图</h4><pre><code>&gt;&gt;w=-<span class="number">6</span>+<span class="built_in">sqrt</span>(<span class="number">10</span>)*randn(<span class="number">1</span>,<span class="number">10000</span>))
&gt;&gt;hist(w)
&gt;&gt;hist(w,<span class="number">50</span>)  %<span class="number">50</span>代表把横坐标分隔为<span class="number">50</span>条
</code></pre><h4 id="单位矩阵">单位矩阵</h4><pre><code>&gt;&gt;eye(<span class="number">4</span>)
<span class="number">1</span> <span class="number">0</span> <span class="number">0</span> <span class="number">0</span>
<span class="number">0</span> <span class="number">1</span> <span class="number">0</span> <span class="number">0</span>
<span class="number">0</span> <span class="number">0</span> <span class="number">1</span> <span class="number">0</span>
<span class="number">0</span> <span class="number">0</span> <span class="number">0</span> <span class="number">1</span>
</code></pre><h4 id="获取矩阵的维数">获取矩阵的维数</h4><pre><code>&gt;&gt;A=[<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]
&gt;&gt;size(A)
ans=
    <span class="number">3</span> <span class="number">2</span>
</code></pre><h4 id="获取向量的长度">获取向量的长度</h4><pre><code>&gt;&gt;v=[<span class="number">1</span> <span class="number">2</span> <span class="number">3</span> <span class="number">4</span>]
&gt;&gt;length(v)
ans=<span class="number">4</span>
</code></pre><h1 id="加载和存储数据">加载和存储数据</h1><h2 id="显示当前path">显示当前path</h2><pre><code><span class="prompt">&gt;&gt;</span>pwd
</code></pre><h2 id="显示当前path所有文件">显示当前path所有文件</h2><pre><code><span class="prompt">&gt;&gt;</span>ls
</code></pre><h2 id="更改path">更改path</h2><pre><code><span class="prompt">&gt;&gt;</span>cd <span class="string">'C:...'</span>
</code></pre><h2 id="加载数据">加载数据</h2><pre><code><span class="prompt">&gt;&gt;</span>load data.dat
或者
<span class="prompt">&gt;&gt;</span>load (<span class="string">'data.data'</span>)
</code></pre><h2 id="查看当前所有变量">查看当前所有变量</h2><pre><code><span class="prompt">&gt;&gt;</span>who
或者
<span class="prompt">&gt;&gt;</span>whos
</code></pre><h2 id="清除变量">清除变量</h2><pre><code><span class="prompt">&gt;&gt;</span>clear
</code></pre><h1 id="对数据进行运算">对数据进行运算</h1><h2 id="假设">假设</h2><pre><code>&gt;&gt;A=[<span class="number">1</span> <span class="number">2</span>;<span class="number">3</span> <span class="number">4</span>;<span class="number">5</span> <span class="number">6</span>]
A=
    <span class="number">1</span> <span class="number">2</span>
    <span class="number">3</span> <span class="number">4</span>
    <span class="number">5</span> <span class="number">6</span>
&gt;&gt;B=[<span class="number">11</span> <span class="number">12</span>;<span class="number">13</span> <span class="number">14</span>;<span class="number">15</span> <span class="number">16</span>]
B=
    <span class="number">11</span> <span class="number">12</span>
    <span class="number">13</span> <span class="number">14</span>
    <span class="number">15</span> <span class="number">16</span>
&gt;&gt;C=[<span class="number">1</span> <span class="number">1</span>;<span class="number">2</span> <span class="number">2</span>]
C=
    <span class="number">1</span> <span class="number">1</span>
    <span class="number">2</span> <span class="number">2</span>
</code></pre><h2 id="矩阵乘法">矩阵乘法</h2><h3 id="矩阵*矩阵">矩阵*矩阵</h3><pre><code>&gt;&gt;A*C  %矩阵乘法
ans=
    <span class="number">5</span> <span class="number">5</span>
    <span class="number">11</span> <span class="number">11</span>
    <span class="number">17</span> <span class="number">17</span>
</code></pre><h3 id="矩阵-*矩阵">矩阵.*矩阵</h3><pre><code>&gt;&gt;A.*B  %对应元素相乘
ans=
    <span class="number">11</span> <span class="number">24</span>
    <span class="number">39</span> <span class="number">56</span>
    <span class="number">75</span> <span class="number">96</span>
</code></pre><h2 id="矩阵转置">矩阵转置</h2><pre><code>&gt;&gt;A'
ans=
    <span class="number">1</span> <span class="number">3</span> <span class="number">5</span>
    <span class="number">2</span> <span class="number">4</span> <span class="number">6</span>
</code></pre><h2 id="向量运算">向量运算</h2><pre><code>&gt;&gt;v=[<span class="number">1</span>;<span class="number">2</span>;<span class="number">3</span>]
v=
    <span class="number">1</span> 
    <span class="number">2</span> 
    <span class="number">3</span>
&gt;&gt;<span class="number">1.</span>/v
ans
    <span class="number">1.00000</span>
    <span class="number">0.50000</span>
    <span class="number">0.33333</span>
&gt;&gt;<span class="built_in">log</span>(v)  %取指数
ans=
    <span class="number">0.00000</span>
    <span class="number">0.69315</span>
    <span class="number">1.09861</span>
&gt;&gt;<span class="built_in">exp</span>(v)  %取对数
ans=
    <span class="number">2.7183</span>
    <span class="number">7.3891</span>
    <span class="number">20.0855</span>
&gt;&gt;-v
v=
    -<span class="number">1</span>
    -<span class="number">2</span>
    -<span class="number">3</span>
&gt;&gt;<span class="built_in">abs</span>(v)  %取绝对值
ans=
    <span class="number">1</span>
    <span class="number">2</span>
    <span class="number">3</span>
&gt;&gt;v+ones(length(v),<span class="number">1</span>)  %等价于v+<span class="number">1</span>，给v的每个元素加<span class="number">1</span>
ans=
    <span class="number">2</span>
    <span class="number">3</span>
    <span class="number">4</span>
</code></pre><h2 id="有用的函数">有用的函数</h2><pre><code>&gt;&gt;a=[<span class="number">1</span> <span class="number">15</span> <span class="number">2</span> <span class="number">0.5</span>];
</code></pre><h3 id="找最值">找最值</h3><pre><code>&gt;&gt;<span class="variable"><span class="keyword">val</span></span>=max(a)
<span class="variable"><span class="keyword">val</span></span>=<span class="number">15</span>
&gt;&gt;[<span class="variable"><span class="keyword">val</span>,ind]</span>=max(a）
<span class="variable"><span class="keyword">val</span></span>=<span class="number">15</span>
ind=<span class="number">2</span>
</code></pre><h3 id="将元素逐个与3比较">将元素逐个与3比较</h3><pre><code>%将元素逐个与<span class="number">3</span>比较
&gt;&gt;a&lt;<span class="number">3</span>
ans=
    <span class="number">1</span> <span class="number">0</span> <span class="number">1</span> <span class="number">1</span>
</code></pre><h3 id="魔方阵">魔方阵</h3><pre><code>%魔方阵--所有的行和列加起来值相同
&gt;&gt;A=magic(<span class="number">3</span>)
&gt;&gt;A=
    <span class="number">8</span> <span class="number">1</span> <span class="number">6</span>
    <span class="number">3</span> <span class="number">5</span> <span class="number">7</span>
    <span class="number">4</span> <span class="number">9</span> <span class="number">2</span>
</code></pre><h3 id="寻找大于/小于/等于某值的元素">寻找大于/小于/等于某值的元素</h3><pre><code>&gt;&gt;[r,c]=find(A&gt;=<span class="number">7</span>) %返回元素所在的行和列
r=
    <span class="number">1</span>
    <span class="number">3</span>
    <span class="number">2</span>
c=
    <span class="number">1</span>
    <span class="number">2</span>
    <span class="number">3</span>
</code></pre><h3 id="向量之和">向量之和</h3><pre><code><span class="prompt">&gt;&gt;</span>sum(a）
<span class="prompt">&gt;&gt;</span>floor(a)
<span class="prompt">&gt;&gt;</span>ceil(a)
</code></pre><h3 id="取矩阵每一列、行的最大元素">取矩阵每一列、行的最大元素</h3><pre><code>&gt;&gt;A=[<span class="number">8</span> <span class="number">1</span> <span class="number">6</span>;<span class="number">3</span> <span class="number">5</span> <span class="number">7</span>;<span class="number">4</span> <span class="number">9</span> <span class="number">2</span>]
A=
    <span class="number">8</span> <span class="number">1</span> <span class="number">6</span>
    <span class="number">3</span> <span class="number">5</span> <span class="number">7</span>
    <span class="number">4</span> <span class="number">9</span> <span class="number">2</span>
&gt;&gt;max(A,[],<span class="number">1</span>)  %<span class="number">1</span>表示每一列的最大值,也可以用max(A)
ans=
    <span class="number">8</span> <span class="number">9</span> <span class="number">7</span>
&gt;&gt;max(A,[],<span class="number">2</span>)  %<span class="number">2</span>表示每一行的最大值
ans=
    <span class="number">8</span>
    <span class="number">7</span>
    <span class="number">9</span>
&gt;&gt;max(max(A))  %取A得最大元素
或者
&gt;&gt;A(:)
&gt;&gt;max(A(:))
</code></pre><h3 id="取对角元素">取对角元素</h3><pre><code>&gt;&gt;<span class="keyword">A</span>=magic(9)<span class="comment">;</span>
&gt;&gt;<span class="keyword">A</span>.*eye(9)<span class="comment">;</span>
&gt;&gt;sum(sum(<span class="keyword">A</span>.*eye(9)))  %对角元素之和
</code></pre><h1 id="画数据">画数据</h1><h2 id="画函数曲线">画函数曲线</h2><pre><code><span class="prompt">&gt;&gt;</span>t=[<span class="number">0</span><span class="symbol">:</span><span class="number">0</span>.<span class="number">01</span><span class="symbol">:</span><span class="number">0</span>.<span class="number">98</span>];
&gt;&gt;y1=sin(<span class="number">2</span>*pi*<span class="number">4</span>*t);
&gt;&gt;plot(t,y1);
&gt;&gt;hold on;
&gt;&gt;y2=cos(<span class="number">2</span>*pi*<span class="number">4</span>*t);
&gt;&gt;plot(t,y2,<span class="string">'r'</span>);
&gt;&gt;xlabel(<span class="string">'time'</span>);
&gt;&gt;ylabel(<span class="string">'value'</span>);
&gt;&gt;legend(<span class="string">'sin'</span>,<span class="string">'cos'</span>)%标记曲线
<span class="prompt">&gt;&gt;</span>title(<span class="string">'my plot'</span>);

&gt;&gt;subplot(<span class="number">1</span>,<span class="number">2</span>,<span class="number">1</span>)  %<span class="number">1</span>行放两张图，编号为<span class="number">1</span>（从左往右第一张）
<span class="prompt">&gt;&gt;</span>plot(t,y1);
&gt;&gt;subplot1，<span class="number">2</span>，<span class="number">2</span>） %<span class="number">1</span>行放两张图，编号为<span class="number">2</span>（从左往右第二张）
<span class="prompt">&gt;&gt;</span>plot(t,y2);
&gt;&gt;axis([<span class="number">0</span>.<span class="number">5</span> <span class="number">1</span> -<span class="number">1</span> <span class="number">1</span>]) %固定横纵坐标值的范围
</code></pre><h2 id="color_bar">color bar</h2><pre><code>&gt;&gt;A=magic<span class="comment">(5)</span>;
&gt;&gt;imagesc<span class="comment">(A)</span>
&gt;&gt;imagesc<span class="comment">(A)</span>,colorbar,colormap gray;<span class="preprocessor">%</span>逗号用于连接命令
</code></pre><h1 id="控制语句">控制语句</h1><h2 id="for">for</h2><pre><code>&gt;&gt;<span class="keyword">for</span> <span class="built_in">i</span>=<span class="number">1</span>:<span class="number">10</span>
    v(<span class="built_in">i</span>)=<span class="number">2</span>^<span class="built_in">i</span>;
&gt;&gt;<span class="keyword">end</span>;
</code></pre><h2 id="while">while</h2><pre><code>&gt;&gt;<span class="keyword">while</span> <span class="built_in">i</span>&lt;=<span class="number">5</span>
    v(<span class="built_in">i</span>)=<span class="number">100</span>;
    <span class="built_in">i</span>=<span class="built_in">i</span>+<span class="number">1</span>;
&gt;&gt;<span class="keyword">end</span>;
</code></pre><h2 id="if">if</h2><pre><code>&gt;&gt;<span class="built_in">i</span>=<span class="number">1</span>;
&gt;&gt;<span class="keyword">while</span> true
&gt;   v(<span class="built_in">i</span>)=<span class="number">999</span>;
&gt;   <span class="built_in">i</span>=<span class="built_in">i</span>+<span class="number">1</span>;
&gt;   <span class="keyword">if</span> <span class="built_in">i</span>==<span class="number">6</span>
&gt;        <span class="keyword">break</span>;
&gt;    <span class="keyword">elseif</span> <span class="built_in">i</span>==<span class="number">7</span>
&gt;        <span class="keyword">break</span>;
&gt;    <span class="keyword">end</span>;
&gt;&gt;<span class="keyword">end</span>;
</code></pre><h1 id="向量化表示（Vectorization)">向量化表示（Vectorization)</h1><p>${h<em>\theta(x)}={\sum</em>(j=0)^n}{\theta_j}{x_j}$=${\theta^T}{x}$</p>
<p>${\theta}={\left[\theta_0\ \theta_1\ theta_2]^T\right}$<br>${x}={\left[\x_0\ \x_1\ x_2]^T\right}$</p>
<h2 id="Unvertorized_implementation">Unvertorized implementation</h2><h3 id="Eg-1">Eg.1</h3><pre><code>prediction=<span class="number">0.0</span>
<span class="keyword">for</span> <span class="built_in">j</span>=<span class="number">1</span>:n+<span class="number">1</span>,
    prediction=prediction+theta(<span class="built_in">j</span>)*x(<span class="built_in">j</span>)
<span class="keyword">end</span>;
</code></pre><h3 id="Eg-2">Eg.2</h3><pre><code><span class="keyword">double</span> prediction=<span class="number">0.0</span>;
<span class="keyword">for</span>(<span class="keyword">int</span> j=<span class="number">0</span>;j&lt;=n;j++)
    prediction+=theta[j]*x[j];
</code></pre><h2 id="Vectorized_implementation">Vectorized implementation</h2><h3 id="Eg-1-1">Eg.1</h3><pre><code>prediction=theta'*x<span class="comment">;</span>
</code></pre><h3 id="Eg-2-1">Eg.2</h3><pre><code><span class="type">double</span> prediction=theta.<span class="built_in">transpose</span>()*x;
</code></pre><h2 id="Gradient_descent的向量化实现">Gradient descent的向量化实现</h2><h3 id="Gradient_descent的数学表达式">Gradient descent的数学表达式</h3><p>${\theta_j}:={\theta<em>j}-{\alpha}{\frac1m}{\sum</em>{i=1}^m}{h_\theta}{(x^(i)-y^(i))}{x_j^(i)}$<br>(for all j)</p>
<h3 id="matlab向量化实现">matlab向量化实现</h3>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="Basic_Operations">Basic Operations</h1><h2 id="算术运算">算术运算</h2><pre><code><span class="prompt">&gt;&gt;</span><span class="number">1<]]>
    </summary>
    
      <category term="machine learning" scheme="http://yoursite.com/tags/machine-learning/"/>
    
      <category term="matlab" scheme="http://yoursite.com/tags/matlab/"/>
    
      <category term="matlab" scheme="http://yoursite.com/categories/matlab/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[resume]]></title>
    <link href="http://yoursite.com/2015/09/21/resume/"/>
    <id>http://yoursite.com/2015/09/21/resume/</id>
    <published>2015-09-21T02:10:02.000Z</published>
    <updated>2015-09-25T06:58:25.796Z</updated>
    <content type="html"><![CDATA[<h2 id="Self-info"><strong>Self-info</strong></h2><blockquote>
<ul>
<li><p>Graduate student in school of Electronics and Computer Engineering(SECE), Peking University. </p>
<ul>
<li><p>Research interests include Pattern Recognition, Machine Learning applied in voice, image and video. I am especially keen to develop voice-driven products and applications.My goal is letting people using <code>Tongue</code> instead of <code>Hands</code>.As an old Chinese saying <code>君子动口不动手</code></p>
</li>
<li><p>Big fan of Data structure and Alogrithm.</p>
</li>
<li><p>Jogging, gym and badminton is my hobbies.After all, health is of greate importance. </p>
</li>
<li><p>Nothing for nothing. Enjoy every day. </p>
</li>
</ul>
</li>
</ul>
</blockquote>
<hr>
<h2 id="Video_about_myself">Video about myself</h2><blockquote>
<p><a href="http://yichihuang.github.io/404.html/" target="_blank" rel="external">Video</a></p>
</blockquote>
<h2 id="Past"><strong>Past</strong></h2><ul>
<li><p>Part-time ACMer<br><img src="http://i.imgur.com/JbJFR8a.jpg" alt="Firework members"><br><img src="http://i.imgur.com/DEKIAmU.jpg" alt=""><br><img src="http://i.imgur.com/5UghiJD.jpg" alt=""></p>
</li>
<li><p>2015.7 Graduted from Beijing University of Posts and Telecommunications(BUPT)<br><img src="http://i.imgur.com/g31V693.jpg" alt=""></p>
</li>
</ul>
<h3 id="Publication"><strong>Publication</strong></h3><blockquote>
<p>《CO-OFDM光纤通信系统接收算法中时序同步的研究》（Research on timing synchronization algorithm of coherent optical OFDM systems)，发表在《光学学报（增刊）》，CIOP-2014-543.<a href="https://github.com/YichiHuang/publications" target="_blank" rel="external">文章链接</a></p>
</blockquote>
<h3 id="Projects"><strong>Projects</strong></h3><blockquote>
<ul>
<li><p>Leader of college student innovation project(national class),responsible for matlab coding and algorithm verification.</p>
</li>
<li><p>Web development——Lab management system. <a href="http://pan.baidu.com/s/1mgvQiEG" target="_blank" rel="external">demo视频地址</a></p>
</li>
</ul>
</blockquote>
<h2 id="Skills"><strong>Skills</strong></h2><h3 id="IT_skills">IT skills</h3><blockquote>
<ul>
<li>Knowledge of WIndows and Windows-based programs</li>
</ul>
<ul>
<li>Experienced in coding with C/C++/Java/Web front/Matlab</li>
</ul>
</blockquote>
<h3 id="English_skills">English skills</h3><blockquote>
<ul>
<li>Have a good command of both spoken and written in English. Have past CET-6.</li>
<li>About half of my courses are taught by foreign teachers. Capable of working with English-speaking colleagues.</li>
<li>All lecture notes are written in English as well as coursework, report,exam paper and any other materials. Chinese and other languages are not allowed.</li>
</ul>
</blockquote>
<h3 id="Teamwork">Teamwork</h3><blockquote>
<ul>
<li><p>I worked in different teams during each term pratical courses, such as personal development plan, mini-term project, labs and management-related coursework(including market research reports and presentations).</p>
</li>
<li><p>As a member of editorial department of Student Union, I have organization term-time events(e.g. promotional activities, proofreading articles etc.)</p>
</li>
<li><p>In 2013, I took part in a college student innovation project and worked with four other classmates on weekly basis. I was responsible for using Matlab to simulate a communication system and verify algorithm. I always finished my task ahead of schedule. </p>
</li>
</ul>
</blockquote>
<h3 id="Problem_solving">Problem solving</h3><blockquote>
<ul>
<li><p>Strongly self-motivated </p>
</li>
<li><p>Dislike attending classes. Hate listening lecturer reading PPT word by word.It wastes of my time.</p>
</li>
<li><p>Favor of problem-driven learning style</p>
</li>
</ul>
</blockquote>
]]></content>
    <summary type="html">
    <![CDATA[<h2 id="Self-info"><strong>Self-info</strong></h2><blockquote>
<ul>
<li><p>Graduate student in school of Electronics and Computer Engineerin]]>
    </summary>
    
      <category term="me" scheme="http://yoursite.com/tags/me/"/>
    
      <category term="photo" scheme="http://yoursite.com/tags/photo/"/>
    
      <category term="photo" scheme="http://yoursite.com/categories/photo/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[poj3253最小堆 Huffman 贪心]]></title>
    <link href="http://yoursite.com/2015/09/20/poj3253/"/>
    <id>http://yoursite.com/2015/09/20/poj3253/</id>
    <published>2015-09-20T11:57:30.000Z</published>
    <updated>2015-09-20T13:33:37.004Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="http://poj.org/problem?id=3253" target="_blank" rel="external">Fence-Repair</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Fence Repair</strong></p>
<p><strong>题目大意：</strong></p>
<p>Farmer John想修围墙，需要一堆木头。木头的数量N(1&lt;=N&lt;=20,000)，每段木头长度为Li(1&lt;=Li&lt;=50,000)。他买了一根无线长的木头，需要锯N-1次，花费的钱和据木头的长度一样。求FJ的最小花费。</p>
<p><strong>输入</strong></p>
<blockquote>
<p>第一行：一个整数N，代表需要锯的木头数量</p>
<p>第二行-第N+1行：每段木头的长度</p>
</blockquote>
<p><strong>输出</strong></p>
<blockquote>
<p>一行：一个整数–最小花费</p>
</blockquote>
<p><strong>样例输入</strong></p>
<blockquote>
<p>3</p>
<p>8</p>
<p>5</p>
<p>8</p>
</blockquote>
<p><strong>样例输出</strong></p>
<blockquote>
<p>34</p>
</blockquote>
<h1 id="分析(Analysis)">分析(Analysis)</h1><h2 id="数据存储"><strong>数据存储</strong></h2><ul>
<li>创建一个一维数组，存每根木头的长度，注意取值范围（可能有大数据），用C++中的<code>long long</code>更保险，否则会<code>WA</code>。</li>
<li>一个<code>long long</code>全局变量存结果<code>ans</code>。 </li>
</ul>
<h2 id="算法"><strong>算法</strong></h2><ul>
<li>类似<code>Huffman Tree</code>，利用<strong>贪心算法</strong>，采用<code>最小堆</code>的结构，自下而上。每次从剩下的木头中选取长度最短的两根，计算二者之和，直到堆中只有一个元素；</li>
<li>一开始，把堆顶元素（最小值）赋值给<code>node[0]</code>，然后取堆的最尾元素插入堆顶，自上而下调整生成最小堆，取堆顶元素<code>node[1]</code>。此时<code>node[0]</code>和<code>node[1]</code>是最小的两个元素，计算二者之和，结果存于<code>node[1]</code>，<code>ans</code>加<code>node[1]</code>计算最小花费，再调整生成最小堆；</li>
<li>重复第二步，直到堆里只有一个元素，循环结束输出<code>ans</code>。</li>
</ul>
<h1 id="代码(Code)">代码(Code)</h1><pre><code><span class="preprocessor">#<span class="keyword">include</span><span class="string">&lt;iostream&gt;</span></span>
<span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;
<span class="keyword">long</span> <span class="keyword">long</span> node[<span class="number">40020</span>],ans;
<span class="comment">/*从根节点开始向下调整*/</span>
<span class="function"><span class="keyword">void</span> <span class="title">down</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> x,<span class="keyword">long</span> <span class="keyword">long</span> size)</span>
</span>{
    <span class="keyword">long</span> <span class="keyword">long</span> i,j,tmp;
    tmp=node[x];
    i=x;
    j=<span class="number">2</span>*i;
    <span class="keyword">while</span>(j&lt;=size)
    {
        <span class="keyword">if</span>(j&lt;size&amp;&amp;node[j]&gt;node[j+<span class="number">1</span>])
            j++;
        <span class="keyword">if</span>(tmp&gt;node[j])
        {
            node[i]=node[j];
            i=j;
            j=<span class="number">2</span>*i;
        }
        <span class="keyword">else</span>
                <span class="keyword">break</span>;
    }
    node[i]=tmp;
}
<span class="comment">/*从根节点开始插入元素建堆*/</span>
<span class="function"><span class="keyword">void</span> <span class="title">buildHeap</span><span class="params">(<span class="keyword">long</span> <span class="keyword">long</span> a[],<span class="keyword">long</span> <span class="keyword">long</span> size)</span>
</span>{
    <span class="keyword">long</span> <span class="keyword">long</span> i;
    <span class="keyword">for</span>(i=size/<span class="number">2</span>; i&gt;<span class="number">0</span>; i--)
    {
        down(i,size);
    }
}
<span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>
</span>{
    <span class="keyword">long</span> <span class="keyword">long</span> n,k;
    <span class="built_in">cin</span>&gt;&gt;n;
    ans=<span class="number">0</span>;
    <span class="keyword">for</span>(k=<span class="number">1</span>; k&lt;=n; k++)
    {
        <span class="built_in">cin</span>&gt;&gt;node[k];
    }
    buildHeap(node,n);
    <span class="keyword">while</span>(n&gt;<span class="number">1</span>)
    {
        node[<span class="number">0</span>]=node[<span class="number">1</span>];<span class="comment">/*取出堆顶元素*/</span>
        node[<span class="number">1</span>]=node[n--];<span class="comment">/*把Node的最后一个元素放到堆顶*/</span>
        down(<span class="number">1</span>,n);<span class="comment">/*向下调整建立最小堆*/</span>
        node[<span class="number">1</span>]+=node[<span class="number">0</span>];
        ans+=node[<span class="number">1</span>];
        down(<span class="number">1</span>,n);
    }
    <span class="built_in">cout</span>&lt;&lt;ans;
    <span class="keyword">return</span> <span class="number">0</span>;
}
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="http://poj.org/problem?id=3253" target="_blank" rel="external">Fence-Repair</a></p>
<h1 id="题目描述(Descript]]>
    </summary>
    
      <category term="Heap" scheme="http://yoursite.com/tags/Heap/"/>
    
      <category term="Huffman" scheme="http://yoursite.com/tags/Huffman/"/>
    
      <category term="POJ" scheme="http://yoursite.com/tags/POJ/"/>
    
      <category term="POJ" scheme="http://yoursite.com/categories/POJ/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[leetcode题目汇总]]></title>
    <link href="http://yoursite.com/2015/09/20/leecode-index/"/>
    <id>http://yoursite.com/2015/09/20/leecode-index/</id>
    <published>2015-09-20T08:32:26.000Z</published>
    <updated>2015-09-20T13:00:11.355Z</updated>
    <content type="html"><![CDATA[<h3 id="Array">Array</h3><ul>
<li><a href="http://yichihuang.github.io/2015/04/09/leetcode-Rotate-Array/" target="_blank" rel="external">旋转数组Rotate-Array</a></li>
</ul>
<h3 id="List">List</h3><ul>
<li><p><a href="http://yichihuang.github.io/leetcode/2015/05/03/leetcode-remove-linked-list-elements/" target="_blank" rel="external">移除链表的元素Remove-Linked-List-Elements</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/03/31/leetcode-Reverse-Linked-List-II/" target="_blank" rel="external">逆转链表Reverse-Linked-List-II</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/21/leetcode-Intersection-of-Two-Linked-Lists/" target="_blank" rel="external">找到两链表的交点Intersection-of-Two-Linked-Lists</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/11/leetcode-linked-list-cycle/" target="_blank" rel="external">链表有环Linked-List-Cycle</a></p>
</li>
</ul>
<h3 id="Stack">Stack</h3><ul>
<li><p><a href="http://yichihuang.github.io/2015/05/03/leetcode-trapping-rain-water/" target="_blank" rel="external">能乘多少水Trapping-Rain-Water</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/05/02/leetcode-min-stack/" target="_blank" rel="external">带有min操作的栈Min-Stack</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/05/02/leetcode-valid-parentheses/" target="_blank" rel="external">判断字符串的括号是否匹配Valid-Parentheses</a></p>
</li>
</ul>
<h3 id="Tree">Tree</h3><ul>
<li><p><a href="http://yichihuang.github.io/2015/04/06/leetcode-binary-tree-preorder-traversal/" target="_blank" rel="external">二叉树遍历Binary-Tree-Preorder-Traversal</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/08/leetcode-validate-binary-search-tree/" target="_blank" rel="external">有效二叉搜索树Validate-Binary-Search-Tree</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/11/leetcode-same-tree/" target="_blank" rel="external">判断两树是否相同Same-Tree</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/11/leetcode-symmetric-tree/" target="_blank" rel="external">判断对称二叉树Symmetric-Tree</a></p>
</li>
<li><p><a href="http://yichihuang.github.io/2015/04/11/leetcode-depth-of-binary-tree/" target="_blank" rel="external">二叉树的最大深度和最小深度Depth-of-Binary-Tree</a></p>
</li>
</ul>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="Array">Array</h3><ul>
<li><a href="http://yichihuang.github.io/2015/04/09/leetcode-Rotate-Array/" target="_blank" rel="external">旋转数]]>
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="Leetcode" scheme="http://yoursite.com/categories/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[POJ算法分类]]></title>
    <link href="http://yoursite.com/2015/09/20/poj-solution/"/>
    <id>http://yoursite.com/2015/09/20/poj-solution/</id>
    <published>2015-09-20T07:00:44.000Z</published>
    <updated>2015-10-15T14:07:09.719Z</updated>
    <content type="html"><![CDATA[<h3 id="OJ上的一些水题(可用来练手和增加自信)">OJ上的一些水题(可用来练手和增加自信)</h3><p>（poj3299,poj2159,poj2739,poj1083,poj2262,poj1503,poj3006,poj2255,poj3094)</p>
<h1 id="初期:">初期:</h1><h3 id="一-基本算法:">一.基本算法:</h3><p>(1)枚举. (poj1753,poj2965)</p>
<p>(2)贪心(poj1328,poj2109,poj2586)</p>
<p>(3)递归和分治法. </p>
<p>(4)递推. </p>
<p>(5)构造法.(poj3295)</p>
<p>(6)模拟法.(poj1068,poj2632,poj1573,poj2993,poj2996)</p>
<h3 id="二-图算法:">二.图算法:</h3><p>(1)图的深度优先遍历和广度优先遍历. </p>
<p>(2)最短路径算法(dijkstra,bellman-ford,floyd,heap+dijkstra) </p>
<p>(poj1860,poj3259,poj1062,poj2253,poj1125,poj2240)</p>
<p>(3)最小生成树算法(prim,kruskal)</p>
<p>(poj1789,poj2485,poj1258,poj3026)</p>
<p>(4)拓扑排序 (poj1094)</p>
<p>(5)二分图的最大匹配 (匈牙利算法) (poj3041,poj3020)</p>
<p>(6)最大流的增广路算法(KM算法). (poj1459,poj3436)</p>
<h3 id="三-数据结构-">三.数据结构.</h3><p>(0)栈（<a href="http://yichihuang.github.io/2015/05/02/poj2082/" target="_blank" rel="external">poj2082</a>）和队列（poj2259)</p>
<p>(1)串 (poj1035,poj3080,poj1936)</p>
<p>(2)排序(快排、归并排(与逆序数有关)、堆排)(poj2388,poj2299)</p>
<p>(3)简单并查集的应用.</p>
<p>(4)哈希表和二分查找等高效查找法(数的Hash,串的Hash)   </p>
<p>(poj3349,poj3274,POJ2151,poj1840,poj2002,<a href="http://yichihuang.github.io/2015/04/17/poj2503-hash/" target="_blank" rel="external">poj2503</a>)</p>
<p>(5)哈夫曼树 (<a href="http://yichihuang.github.io/2015/09/20/poj3253/" target="_blank" rel="external">poj3253</a>)</p>
<p>(6)堆 (<a href="http://yichihuang.github.io/2015/04/10/poj2051/" target="_blank" rel="external">poj2051</a>)</p>
<p>(7)trie树(静态建树、动态建树) (<a href="http://yichihuang.github.io/poj/2015/04/17/poj2503/" target="_blank" rel="external">poj2503</a>,<a href="http://yichihuang.github.io/2015/04/17/poj2503/" target="_blank" rel="external">poj3630</a>,poj2001)</p>
<h3 id="四-简单搜索">四.简单搜索</h3><p>(1)深度优先搜索 </p>
<p>(poj2488,poj3083,poj3009,poj1321,poj2251)</p>
<p>(2)广度优先搜索</p>
<p>(poj3278,poj1426,poj3126,poj3087.poj3414)</p>
<p>(3)简单搜索技巧和剪枝</p>
<p>(poj2531,poj1416,poj2676,1129)</p>
<h3 id="五-动态规划">五.动态规划</h3><p>(1)背包问题. (poj1837,poj1276)</p>
<p>(2)型如下表的简单DP(可参考lrj的书 page149): </p>
<pre><code>1.E[j]=opt{D[i]+w(i,j)} 

  (poj3267,poj1836,poj1260,poj2533)

2.E[<span class="link_label">i,j</span>]=opt{D[<span class="link_label">i-1,j</span>]+xi,D[<span class="link_label">i,j-1</span>]+yj,D[<span class="link_label">i-1</span>][<span class="link_reference">j-1</span>]+zij} (最长公共子序列)    

  (poj3176,poj1080,poj1159)

3.C[i,j]=w[i,j]+opt{C[i,k-1]+C[k,j]}.(最优二分检索树问题) 
</code></pre><h3 id="六-数学">六.数学</h3><p>(1)组合数学: </p>
<pre><code><span class="number">1.</span>加法原理和乘法原理. 

<span class="number">2.</span>排列组合. 

<span class="number">3.</span>递推关系. 
</code></pre><p>(POJ3252,poj1850,poj1019,poj1942)</p>
<p>(2)数论. </p>
<pre><code><span class="number">1.</span>素数与整除问题 

<span class="number">2.</span>进制位. 

<span class="number">3.</span>同余模运算.
</code></pre><p>(poj2635, poj3292,poj1845,poj2115)</p>
<p>(3)计算方法. </p>
<pre><code><span class="number">1.</span>二分法求解单调函数相关知识.
</code></pre><p>(poj3273,poj3258,poj1905,poj3122)</p>
<h3 id="七-计算几何学-">七.计算几何学.</h3><p>(1)几何公式.</p>
<p>(2)叉积和点积的运用(如线段相交的判定,点到线段的距离等). </p>
<p>(poj2031,poj1039)</p>
<p>(3)多边型的简单算法(求面积)和相关判定(点在多边型内,多边型是否相交) </p>
<p>(poj1408,poj1584)</p>
<p>(4)凸包.  </p>
<p>(poj2187,poj1113)</p>
<h1 id="中级:">中级:</h1><h3 id="一-基本算法:-1">一.基本算法:</h3><p>(1)C++的标准模版库的应用. (poj3096,poj3007)</p>
<p>(2)较为复杂的模拟题的训练</p>
<p>(poj3393,poj1472,poj3371,poj1027,poj2706)</p>
<h3 id="二-图算法:-1">二.图算法:</h3><p>(1)差分约束系统的建立和求解. (poj1201,poj2983)</p>
<p>(2)最小费用最大流(poj2516,poj2516,poj2195)</p>
<p>(3)双连通分量(poj2942)</p>
<p>(4)强连通分支及其缩点.(poj2186)</p>
<p>(5)图的割边和割点(poj3352)</p>
<p>(6)最小割模型、网络流规约(poj3308)</p>
<h3 id="三-数据结构--1">三.数据结构.</h3><p>(1)线段树. (poj2528,poj2828,poj2777,poj2886,poj2750)</p>
<p>(2)静态二叉检索树. (poj2482,poj2352,<a href="http://yichihuang.github.io/2015/04/08/poj2418/" target="_blank" rel="external">poj2418</a>)</p>
<p>(3)树状树组(poj1195,poj3321)</p>
<p>(4)RMQ. (poj3264,poj3368)</p>
<p>(5)并查集的高级应用. (poj1703,2492)</p>
<p>(6)KMP算法. (<a href="http://yichihuang.github.io/2015/04/16/poj1961/" target="_blank" rel="external">poj1961</a>,<a href="http://yichihuang.github.io/2015/04/16/poj2406/" target="_blank" rel="external">poj2406</a>,<a href="http://yichihuang.github.io/2015/04/16/poj2752/" target="_blank" rel="external">poj2752</a>)</p>
<h3 id="四-搜索">四.搜索</h3><p>(1)最优化剪枝和可行性剪枝 </p>
<p>(2)搜索的技巧和优化 (poj3411,poj1724)</p>
<p>(3)记忆化搜索(poj3373,poj1691)</p>
<h3 id="五-动态规划-1">五.动态规划</h3><p>(1)较为复杂的动态规划(如动态规划解特别的施行商问题等)<br>        (poj1191,poj1054,poj3280,poj2029,poj2948,poj1925,poj3034)</p>
<p>(2)记录状态的动态规划. (poj3254,poj2411,poj1185)</p>
<p>(3)树型动态规划(poj2057,poj1947,poj2486,poj3140)</p>
<h3 id="六-数学-1">六.数学</h3><p>(1)组合数学: </p>
<pre><code> <span class="number">1.</span>容斥原理. 

<span class="number">2.</span>抽屉原理. 

<span class="number">3.</span>置换群与Polya定理

 (poj1286,poj2409,poj3270,poj1026). 

<span class="number">4.</span>递推关系和母函数. 
</code></pre><p>(2)数学. </p>
<pre><code> <span class="number">1.</span>高斯消元法

 <span class="comment">(poj2947,poj1487, poj2065,poj1166,poj1222)</span>

<span class="number">2.</span>概率问题. <span class="comment">(poj3071,poj3440)</span>

<span class="number">3.</span>GCD、扩展的欧几里德<span class="comment">(中国剩余定理)</span> <span class="comment">(poj3101)</span> 
</code></pre><p>(3)计算方法. </p>
<pre><code><span class="number">1.0</span>/<span class="number">1</span>分数规划. (poj2976)

<span class="number">2.</span>三分法求解单峰(单谷)的极值. 

<span class="number">3.</span>矩阵法(poj3150,poj3422,poj3070)

<span class="number">4.</span>迭代逼近(poj3301)
</code></pre><p>(4)随机化算法(poj3318,poj2454)</p>
<p>(5)杂题.</p>
<pre><code><span class="list">(<span class="keyword">poj1870</span>,poj3296,poj3286,poj1095)</span>
</code></pre><h3 id="七-计算几何学--1">七.计算几何学.</h3><p>(1)坐标离散化. </p>
<p>(2)扫描线算法(例如求矩形的面积和周长并,常和线段树或堆一起使用). </p>
<p>(poj1765,poj1177,poj1151,poj3277,poj2280,poj3004)</p>
<p>(3)多边形的内核(半平面交)(poj3130,poj3335)</p>
<p>(4)几何工具的综合应用.</p>
<p>(poj1819,poj1066,poj2043,poj3227,poj2165,poj3429)</p>
<h1 id="高级:">高级:</h1><h3 id="一-基本算法要求:">一.基本算法要求:</h3><p>(1)代码快速写成,精简但不失风格  </p>
<p>(poj2525,poj1684,poj1421,poj1048,poj2050,poj3306)</p>
<p>(2)保证正确性和高效性.  poj3434</p>
<h3 id="二-图算法:-2">二.图算法:</h3><p>(1)度限制最小生成树和第K最短路. (poj1639)</p>
<p>(2)最短路,最小生成树,二分图,最大流问题的相关理论(主要是模型建立和求解)</p>
<p>(poj3155,poj2112,poj1966,poj3281,poj1087,poj2289,poj3216,poj2446）</p>
<p>(3)最优比率生成树.  (poj2728)</p>
<p>(4)最小树形图(poj3164)</p>
<p>(5)次小生成树. </p>
<p>(6)无向图、有向图的最小环   </p>
<h3 id="三-数据结构--2">三.数据结构.</h3><p>(1)trie图的建立和应用. (poj2778)</p>
<p>(2)LCA和RMQ问题(LCA(最近公共祖先问题) 有离线算法(并查集+dfs) 和 在线算法 (RMQ+dfs)).(poj1330)</p>
<p>(3)双端队列和它的应用(维护一个单调的队列,常常在动态规划中起到优化状态转移的目的).  (poj2823)</p>
<p>(4)左偏树(可合并堆).  </p>
<p>(5)后缀树(非常有用的数据结构,也是赛区考题的热点). </p>
<p>(poj3415,poj3294)</p>
<h3 id="四-搜索-1">四.搜索</h3><p>(1)较麻烦的搜索题目训练</p>
<p>(poj1069,poj3322,poj1475,poj1924,poj2049,poj3426)</p>
<p>(2)广搜的状态优化:利用M进制数存储状态、转化为串用hash表判重、按位压缩存储状态、双向广搜、A*算法.</p>
<p>(poj1768,poj1184,poj1872,poj1324,poj2046,poj1482)</p>
<p>(3)深搜的优化:尽量用位运算、一定要加剪枝、函数参数尽可能少、层数不易过大、可以考虑双向搜索或者是轮换搜索、IDA*算法. </p>
<p>(poj3131,poj2870,poj2286)</p>
<h3 id="五-动态规划-2">五.动态规划</h3><p>(1)需要用数据结构优化的动态规划.</p>
<p>(poj2754,poj3378,poj3017)</p>
<p>(2)四边形不等式理论. </p>
<p>(3)较难的状态DP(poj3133)</p>
<h3 id="六-数学-2">六.数学</h3><p>(1)组合数学. </p>
<pre><code> <span class="number">1.</span>MoBius反演(poj2888,poj2154)

<span class="number">2.</span>偏序关系理论. 
</code></pre><p>(2)博奕论. </p>
<pre><code><span class="number">1.</span>极大极小过程(poj3317,poj1085)

<span class="number">2.</span>Nim问题. 
</code></pre><h3 id="七-计算几何学--2">七.计算几何学.</h3><p>(1)半平面求交(poj3384,poj2540)</p>
<p>(2)可视图的建立(poj2966)</p>
<p>(3)点集最小圆覆盖. </p>
<p>(4)对踵点(poj2079)</p>
<h3 id="八-综合题-">八.综合题.</h3><p>   (poj3109,poj1478,poj1462,poj2729,poj2048,poj3336,poj3315,poj2148,poj1263)</p>
]]></content>
    <summary type="html">
    <![CDATA[<h3 id="OJ上的一些水题(可用来练手和增加自信)">OJ上的一些水题(可用来练手和增加自信)</h3><p>（poj3299,poj2159,poj2739,poj1083,poj2262,poj1503,poj3006,poj2255,poj3094)</p>
<h1 ]]>
    </summary>
    
      <category term="POJ" scheme="http://yoursite.com/tags/POJ/"/>
    
      <category term="POJ" scheme="http://yoursite.com/categories/POJ/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[记15级北大信息工程学院计算机1班第一次班聚]]></title>
    <link href="http://yoursite.com/2015/09/20/My-Gallery/"/>
    <id>http://yoursite.com/2015/09/20/My-Gallery/</id>
    <published>2015-09-20T02:52:05.000Z</published>
    <updated>2015-09-20T10:10:34.210Z</updated>
    <content type="html"><![CDATA[<p><img src="http://i.imgur.com/lyd69rQ.jpg" alt=""></p>
<h4 id="计算机1班第一次班级聚会"><strong>计算机1班第一次班级聚会</strong></h4><p>经过两个礼拜的PS，陈辰同学终于把聚会的照片PO出来了。计算机1班第一次聚会在哈工大的筒子楼（莘语轩），东北菜馆。作为一个在北京上了四年学的正宗南方人表示，鱼香茄子真的好难吃。虽然菜没点好不咋好吃，但大家玩得都很开心。对了，陈辰你还有半打啤酒下次聚会必须喝掉啊。</p>
<p>据说隔壁计算机2班的同学都很能喝，所以下次是不是要考虑和二班联谊一下呢？</p>
<p>看到图片，钟尚儒同学表示又多了PS的素材。</p>
<p>最后，祝愿大家能开心快乐的度过未来的研究生三年。可能是在学校学习的最后三年了，珍惜。</p>
<p>一起奔向远大前程！</p>
<h4 id="大家都很正常的合照"><strong>大家都很正常的合照</strong></h4><p><img src="http://i.imgur.com/lyd69rQ.jpg" alt=""></p>
<h4 id="第二张照片，陈辰你是要飞起来了吗。O(∩_∩)O哈哈哈~"><strong>第二张照片，陈辰你是要飞起来了吗。O(∩_∩)O哈哈哈~</strong></h4><p><img src="http://i.imgur.com/IuRPEDy.jpg" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<p><img src="http://i.imgur.com/lyd69rQ.jpg" alt=""></p>
<h4 id="计算机1班第一次班级聚会"><strong>计算机1班第一次班级聚会</strong></h4><p>经过两个礼拜的PS，陈辰同学终于把聚会的照片PO]]>
    </summary>
    
      <category term="photo" scheme="http://yoursite.com/tags/photo/"/>
    
      <category term="计算机1班" scheme="http://yoursite.com/tags/%E8%AE%A1%E7%AE%97%E6%9C%BA1%E7%8F%AD/"/>
    
      <category term="photo" scheme="http://yoursite.com/categories/photo/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[长沙市一中深港小分队喜迎韶哥莅临大学城]]></title>
    <link href="http://yoursite.com/2015/09/19/photo-changshayizhongjuhui/"/>
    <id>http://yoursite.com/2015/09/19/photo-changshayizhongjuhui/</id>
    <published>2015-09-19T03:08:00.000Z</published>
    <updated>2015-09-20T10:13:55.389Z</updated>
    <content type="html"><![CDATA[<h4 id="港大的韶哥来大学城"><strong>港大的韶哥来大学城</strong></h4><p>开学第一周，韶哥特意从香港过来深圳，顺便来了大学城看我们。在这边的一中共四位：心一、蔡轩、贺思颖和我。心一和蔡轩都在汇丰，贺思颖和我在信工。</p>
<p>一起吃了晚饭，之后去唱了K。</p>
<h4 id="汇丰楼下的尚书房合照"><strong>汇丰楼下的尚书房合照</strong></h4><p>服务员帮忙拍的，拍完后说：“后面那位男同学没笑”</p>
<p>我们看过来一看，“噗…韶哥你的表情怎么这么严肃…”<br><img src="http://i.imgur.com/HAZUfFk.jpg" alt=""></p>
<h4 id="爱学习的girl"><strong>爱学习的girl</strong></h4><p>第一周真是太忙了，各种报告各种会。于是趁着等菜的间隙确认了一下第二天的安排，结果被心一偷拍了。</p>
<p><img src="http://i.imgur.com/Ns9CP0F.jpg" alt=""></p>
]]></content>
    <summary type="html">
    <![CDATA[<h4 id="港大的韶哥来大学城"><strong>港大的韶哥来大学城</strong></h4><p>开学第一周，韶哥特意从香港过来深圳，顺便来了大学城看我们。在这边的一中共四位：心一、蔡轩、贺思颖和我。心一和蔡轩都在汇丰，贺思颖和我在信工。</p>
<p>一起吃了晚饭，之后]]>
    </summary>
    
      <category term="photo" scheme="http://yoursite.com/tags/photo/"/>
    
      <category term="长沙市一中" scheme="http://yoursite.com/tags/%E9%95%BF%E6%B2%99%E5%B8%82%E4%B8%80%E4%B8%AD/"/>
    
      <category term="photo" scheme="http://yoursite.com/categories/photo/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[leetcode Remove Linked List Elements]]></title>
    <link href="http://yoursite.com/2015/05/03/leetcode-remove-linked-list-elements/"/>
    <id>http://yoursite.com/2015/05/03/leetcode-remove-linked-list-elements/</id>
    <published>2015-05-03T12:08:26.000Z</published>
    <updated>2015-09-20T23:51:34.608Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/remove-linked-list-elements/" target="_blank" rel="external">remove-linked-list-elements</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Remove Linked List Elements</strong></p>
<p>Remove all elements from a linked list of integers that have value val.</p>
<p>Example<br>Given: <code>1 --&gt; 2 --&gt; 6 --&gt; 3 --&gt; 4 --&gt; 5 --&gt; 6, val = 6</code><br>Return: <code>1 --&gt; 2 --&gt; 3 --&gt; 4 --&gt; 5</code></p>
<p><strong>移除链表元素</strong></p>
<p>给定一个整数，要求从链表中移除包含这个整数的所有结点。</p>
<p>例如：</p>
<p>给定链表和值：<code>1 --&gt; 2 --&gt; 6 --&gt; 3 --&gt; 4 --&gt; 5 --&gt; 6, val = 6</code></p>
<p>返回：<code>1 --&gt; 2 --&gt; 3 --&gt; 4 --&gt; 5</code></p>
<h1 id="分析（Analysis)">分析（Analysis)</h1><p>这题并不难。起初我考虑到头结点是否需要删去的问题，把问题分为了两部分解决。后来，看了网上的思路，有更好的办法可以把所有问题归为一类，那就是在头结点之前假定一个空闲结点<code>newhead</code>，然后把<code>newhead-&gt;next</code>指向<code>head</code>即可。最后返回<code>newhead-&gt;next</code>。</p>
<h1 id="代码(Code)">代码(Code)</h1><pre><code>/**
 * <span class="type">Definition</span> <span class="keyword">for</span> singly-linked <span class="built_in">list</span>.
 * <span class="keyword">struct</span> <span class="type">ListNode</span> {
 *     <span class="built_in">int</span> <span class="keyword">val</span>;
 *     <span class="type">ListNode</span> *next;
 *     <span class="type">ListNode</span>(<span class="built_in">int</span> x) : <span class="keyword">val</span>(x), next(<span class="type">NULL</span>) {}
 * };
 */
<span class="keyword">class</span> <span class="type">Solution</span> {
public:
    <span class="type">ListNode</span>* removeElements(<span class="type">ListNode</span>* head, <span class="built_in">int</span> <span class="keyword">val</span>) {
        <span class="type">ListNode</span>* newhead=<span class="keyword">new</span> <span class="type">ListNode</span>(-<span class="number">1</span>);
        <span class="type">ListNode</span>* pre=newhead;
        <span class="type">ListNode</span>* cur=head;
        newhead-&gt;next=head;
        <span class="keyword">while</span>(cur){
            <span class="keyword">if</span>(cur-&gt;<span class="keyword">val</span>==<span class="keyword">val</span>){
                cur=cur-&gt;next;
                pre-&gt;next=cur;
            }
            <span class="keyword">else</span>{
                pre=cur;
                cur=cur-&gt;next;
            }
        }
        return newhead-&gt;next;
    }
};
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/remove-linked-list-elements/" target="_blank" rel="external">remove-linked-]]>
    </summary>
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="list" scheme="http://yoursite.com/tags/list/"/>
    
      <category term="Leetcode" scheme="http://yoursite.com/categories/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[leetcode Trapping Rain Water]]></title>
    <link href="http://yoursite.com/2015/05/03/leetcode-trapping-rain-water/"/>
    <id>http://yoursite.com/2015/05/03/leetcode-trapping-rain-water/</id>
    <published>2015-05-03T12:04:58.000Z</published>
    <updated>2015-09-20T12:07:39.935Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/trapping-rain-water/" target="_blank" rel="external">trapping-rain-water</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Trapping rain water</strong></p>
<p>Given n non-negative integers representing an elevation map where the width of each bar is 1, compute how much water it is able to trap after raining.</p>
<p>For example,<br>Given [0,1,0,2,1,0,1,3,2,1,2,1], return 6.</p>
<p><img src="http://i.imgur.com/OvjszIy.png" alt=""></p>
<p>The above elevation map is represented by array [0,1,0,2,1,0,1,3,2,1,2,1]. In this case, 6 units of rain water (blue section) are being trapped. Thanks Marcos for contributing this image!</p>
<h1 id="分析(Analysis)">分析(Analysis)</h1><p>这道题放到了<code>stack</code>这一类里，然而一眼望过去这是一道数学几何体。</p>
<h2 id="方法一(时间复杂度O(n))">方法一(时间复杂度O(n))</h2><pre><code>从两边往中间扫描，对每一个<span class="escape">`h</span>eight[i]<span class="escape">`来</span>说，蓄水量等于左右两边第二高的柱子减去<span class="escape">`h</span>eight[i]<span class="escape">`的</span>值。最后把所有柱子的蓄水量加起来。
</code></pre><h1 id="代码(Code)">代码(Code)</h1><h2 id="方法一">方法一</h2><pre><code><span class="keyword">class</span> Solution {
<span class="keyword">public</span>:
    <span class="built_in">int</span> trap(vector&lt;<span class="built_in">int</span>&gt;&amp; height) {
        <span class="built_in">int</span> ans=<span class="number">0</span>;
        <span class="built_in">int</span> <span class="built_in">len</span>=height.size();
        <span class="built_in">int</span> <span class="built_in">left</span>=<span class="number">0</span>,<span class="built_in">right</span>=<span class="built_in">len</span>-<span class="number">1</span>,secHeight;
        <span class="keyword">while</span>(<span class="built_in">left</span>&lt;<span class="built_in">right</span>){
            <span class="keyword">if</span>(height[<span class="built_in">left</span>]&lt;height[<span class="built_in">right</span>]){
                secHeight=max(height[<span class="built_in">left</span>],secHeight);
                ans+=secHeight-height[<span class="built_in">left</span>];
                <span class="built_in">left</span>++;
            }
            <span class="keyword">else</span>{
                secHeight=max(height[<span class="built_in">right</span>],secHeight);
                ans+=secHeight-height[<span class="built_in">right</span>];
                <span class="built_in">right</span>--;
            }
        }
        return ans;
    }
};
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/trapping-rain-water/" target="_blank" rel="external">trapping-rain-water</a]]>
    </summary>
    
      <category term="Math" scheme="http://yoursite.com/tags/Math/"/>
    
      <category term="Stack" scheme="http://yoursite.com/tags/Stack/"/>
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="Leetcode" scheme="http://yoursite.com/categories/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[leetcode Min Stack]]></title>
    <link href="http://yoursite.com/2015/05/02/leetcode-min-stack/"/>
    <id>http://yoursite.com/2015/05/02/leetcode-min-stack/</id>
    <published>2015-05-02T12:14:32.000Z</published>
    <updated>2015-09-20T12:16:34.546Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/min-stack/" target="_blank" rel="external">min-stack</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Min Stack</strong></p>
<p>Design a stack that supports push, pop, top, and retrieving the minimum element in constant time.</p>
<ul>
<li><p>push(x) – Push element x onto stack.</p>
</li>
<li><p>pop() – Removes the element on top of the stack.</p>
</li>
<li><p>top() – Get the top element.</p>
</li>
<li><p>getMin() – Retrieve the minimum element in the stack.</p>
</li>
</ul>
<p><strong>带有最小值操作的栈</strong></p>
<p>设计一个栈使其支持压入、弹出、返回栈顶元素和及时返回栈的最小元素。</p>
<ul>
<li><p>push(x) –把元素x压入栈中</p>
</li>
<li><p>pop() –移除栈顶元素</p>
</li>
<li><p>top() –得带栈顶元素</p>
</li>
<li><p>getMin() –获得栈的最小元素</p>
</li>
</ul>
<h1 id="分析(Analysis)">分析(Analysis)</h1><p>本题用C++做非常简单，因为C++里的封装了stack的基本操作。</p>
<p>本题的难点在于如果获得最小元素，这里要求时间复杂度为O(1)，那么通过遍历的方法找最小值的方法在这里是行不通的。</p>
<p>我们可以通过维护一个<code>minStack</code>的栈，栈顶元素是当前栈里所有元素的最小值，只要把<code>minStack</code>的栈顶元素返回即可。</p>
<h1 id="代码(Code)">代码(Code)</h1><pre><code><span class="keyword">class</span> MinStack {
<span class="keyword">public</span>:
    <span class="function"><span class="keyword">void</span> <span class="title">push</span><span class="params">(<span class="keyword">int</span> x)</span> </span>{
        s.push(x);
        <span class="keyword">if</span>(minS.empty()||minS.top()&gt;=x)
            minS.push(x);
    }

    <span class="function"><span class="keyword">void</span> <span class="title">pop</span><span class="params">()</span> </span>{
        <span class="keyword">if</span>(s.top()==minS.top())
                minS.pop();
        s.pop();
    }

    <span class="function"><span class="keyword">int</span> <span class="title">top</span><span class="params">()</span> </span>{
        <span class="keyword">return</span> s.top();
    }

    <span class="function"><span class="keyword">int</span> <span class="title">getMin</span><span class="params">()</span> </span>{
        <span class="keyword">return</span> minS.top();
    }
<span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; s;
<span class="built_in">stack</span>&lt;<span class="keyword">int</span>&gt; minS;
};
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/min-stack/" target="_blank" rel="external">min-stack</a></p>
<h1 id="题目描述(D]]>
    </summary>
    
      <category term="Stack" scheme="http://yoursite.com/tags/Stack/"/>
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="Leetcode" scheme="http://yoursite.com/categories/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[leetcode Valid Parentheses]]></title>
    <link href="http://yoursite.com/2015/05/02/leetcode-valid-parentheses/"/>
    <id>http://yoursite.com/2015/05/02/leetcode-valid-parentheses/</id>
    <published>2015-05-02T12:12:49.000Z</published>
    <updated>2015-09-20T12:14:19.046Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/valid-parentheses/" target="_blank" rel="external">valid-parentheses/</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Valid Parentheses</strong></p>
<p>Given a string containing just the characters ‘(‘, ‘)’, ‘{‘, ‘}’, ‘[‘ and ‘]’, determine if the input string is valid.</p>
<p>The brackets must close in the correct order, “()” and “()[]{}” are all valid but “(]” and “([)]” are not.</p>
<p><strong>有效的括号</strong></p>
<p>给一个字符串只包含<code>&#39;(&#39;, &#39;)&#39;, &#39;{&#39;, &#39;}&#39;, &#39;[&#39;  &#39;]&#39;</code>，判断这个字符串时候合法。</p>
<p>括号必须按照规律匹配，如<code>&quot;()&quot; &quot;()[]{}&quot;</code> 都是合法的，但是<code>&quot;(]&quot; 和 &quot;([)]&quot;</code>不合法.</p>
<h1 id="分析(Analysis)">分析(Analysis)</h1><p>用一个栈模拟，遇到左括号则压入栈，遇到右括号则与栈顶进行匹配，如果失配则返回<code>false</code>，如果匹配就弹出。如果没有右括号，返回<code>false</code>。最后，如果栈不为空，则说明还有左括号没有匹配，返回<code>false</code>，如果栈不为空，则说明所有括号都已经匹配返回<code>true</code>，最终返回<code>st.empty()</code>即可。</p>
<h1 id="代码(Code)">代码(Code)</h1><pre><code><span class="keyword">class</span> Solution {
<span class="keyword">public</span>:
    <span class="function"><span class="keyword">bool</span> <span class="title">isValid</span><span class="params">(<span class="built_in">string</span> s)</span> </span>{
        <span class="built_in">stack</span>&lt;<span class="keyword">char</span>&gt; st;
        <span class="keyword">char</span> c;
        <span class="keyword">for</span>(<span class="keyword">int</span> i=<span class="number">0</span>;i&lt;s.length();i++){
            <span class="keyword">if</span>(s[i]==<span class="string">'('</span>||s[i]==<span class="string">'{'</span>||s[i]==<span class="string">'['</span>)
                st.push(s[i]);
            <span class="keyword">if</span>(s[i]==<span class="string">')'</span>||s[i]==<span class="string">'}'</span>||s[i]==<span class="string">']'</span>)
            {
                   <span class="keyword">if</span>(st.empty())
                    <span class="keyword">return</span> <span class="literal">false</span>;
                <span class="keyword">else</span>
                {
                    c=st.top();
                    <span class="keyword">if</span>((s[i]==<span class="string">')'</span>&amp;&amp;c!=<span class="string">'('</span>)||(s[i]==<span class="string">'}'</span>&amp;&amp;c!=<span class="string">'{'</span>)||(s[i]==<span class="string">']'</span>&amp;&amp;c!=<span class="string">'['</span>))
                        <span class="keyword">return</span> <span class="literal">false</span>;
                    <span class="keyword">else</span>
                        st.pop();
                }
            }
        }
            <span class="keyword">return</span> st.empty();
    }
};
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="https://leetcode.com/problems/valid-parentheses/" target="_blank" rel="external">valid-parentheses/</a></]]>
    </summary>
    
      <category term="Stack" scheme="http://yoursite.com/tags/Stack/"/>
    
      <category term="leetcode" scheme="http://yoursite.com/tags/leetcode/"/>
    
      <category term="Leetcode" scheme="http://yoursite.com/categories/Leetcode/"/>
    
  </entry>
  
  <entry>
    <title><![CDATA[poj2082栈的应用之给定每个矩形的长和宽求可以形成的最大矩形]]></title>
    <link href="http://yoursite.com/2015/05/02/poj2082/"/>
    <id>http://yoursite.com/2015/05/02/poj2082/</id>
    <published>2015-05-02T12:10:27.000Z</published>
    <updated>2015-09-20T12:12:24.982Z</updated>
    <content type="html"><![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="http://poj.org/problem?id=2082" target="_blank" rel="external">Terrible Sets</a></p>
<h1 id="题目描述(Description)">题目描述(Description)</h1><p><strong>Terrible Sets（糟糕的集合）</strong></p>
<p>假设N是自然数集合，R是表示所有实数的集合，wi,hi(i=1…n)是N里的一些元素，w0=0.<br>定义集合B={<x,y>|x,y $\in$ R,存在i&gt;0使得0&lt;=y&lt;=hi,$\prod<em>{0\leqj\leq(i-1)}wj \leq x \leq \prod</em>{0\leqj\leqi}wj$} </x,y></p>
<p>定义集合S={A|A=WH,W,H$\in$ $R^+$,在N中存在x0,y0使得集合T={<x,y>|x,y$\in$ $R^+$,x0 &lt;= x &lt;= x0 +W, y0 &lt;= y &lt;= y0 + H} 包含于集合B}</x,y></p>
<p>你的任务是求S的最大值。</p>
<p><strong>题目大意：</strong>这个题目描述的好绕，其实大意是：紧贴想x轴有一些相互挨着的矩形，给定连续的宽和长，求出最大的连续矩形的面积。</p>
<p><strong>样例输入</strong></p>
<pre><code><span class="number">3</span>
<span class="number">1</span> <span class="number">2</span>
<span class="number">3</span> <span class="number">4</span>
<span class="number">1</span> <span class="number">2</span>
<span class="number">3</span>
<span class="number">3</span> <span class="number">4</span>
<span class="number">1</span> <span class="number">2</span>
<span class="number">3</span> <span class="number">4</span>
-<span class="number">1</span>
</code></pre><p><strong>样例输出</strong></p>
<pre><code><span class="number">12</span>
<span class="number">14</span>
</code></pre><h1 id="分析(Analysis)">分析(Analysis)</h1><p>这道题的题目描述实在太晦涩。</p>
<p>直接看样例：</p>
<p>Case#1：</p>
<p><img src="http://i.imgur.com/ZFuAr1v.png" alt=""></p>
<p>Case#2:</p>
<p><img src="http://i.imgur.com/hYS5TNz.png" alt=""></p>
<ol>
<li>可以用一个栈<code>stact&lt;Node&gt;s</code>模拟，将矩形入栈，如果矩形的高度递增，即<code>rect.h</code>大于栈顶矩形的高度，则将此矩形入栈；</li>
<li>如果矩形的高度比当前栈顶矩形的高度小，此时该矩形不入栈，但是要计算此高度的矩形与之前入栈的矩形所能围成的最大矩形，矩形高度已知为<code>rect.h</code>，主要计算到达的最大宽度。最大宽度设为<code>width</code>,初始化为0，如果<code>栈非空&amp;&amp;s.top().h&gt;rect.h</code>,则<code>width+=s.top.w</code>，然后把新的大矩形压入栈；</li>
<li>注意到测试2的情况，最后还要扫描所有入栈的矩形，否则如果最后一个入栈的矩形高度比栈顶矩形高度大小，则会少加一部分面积。</li>
</ol>
<h1 id="代码(Code)">代码(Code)</h1><pre><code><span class="preprocessor">#<span class="keyword">include</span><span class="string">&lt;cstdio&gt;</span></span>
<span class="preprocessor">#<span class="keyword">include</span><span class="string">&lt;stack&gt;</span></span>
<span class="keyword">using</span> <span class="keyword">namespace</span> <span class="built_in">std</span>;
<span class="keyword">struct</span> Node{
    <span class="keyword">int</span> w,h;<span class="comment">//宽和高 </span>
}rect;
<span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span>
</span>{
    <span class="keyword">int</span> n,ans,curArea,width;
    <span class="keyword">while</span>(<span class="built_in">scanf</span>(<span class="string">"%d"</span>,&amp;n)&amp;&amp;n!=-<span class="number">1</span>)
    {
        ans=<span class="number">0</span>;
        <span class="built_in">stack</span>&lt;Node&gt; s;
        <span class="keyword">while</span>(n--)
        {
            <span class="built_in">scanf</span>(<span class="string">"%d%d"</span>,&amp;rect.w,&amp;rect.h);
            <span class="keyword">if</span>(s.empty()||rect.h&gt;=s.top().h){
                s.push(rect);<span class="comment">//如果栈为空或矩形高度递增，则压入栈； </span>
            }
            <span class="keyword">else</span>{
                width=<span class="number">0</span>;
                curArea=<span class="number">0</span>;
                <span class="keyword">while</span>(!s.empty()&amp;&amp;s.top().h&gt;rect.h)
                {<span class="comment">//计算最大宽度 </span>
                    width+=s.top().w;
                    curArea=width*s.top().h;
                    <span class="keyword">if</span>(curArea&gt;ans)
                        ans=curArea;
                     s.pop();
                }
                <span class="comment">//将新的大矩形压入栈</span>
                width+=rect.w;
                rect.w=width;
                 s.push(rect);
            }
        }
        width=<span class="number">0</span>;
        curArea=<span class="number">0</span>;
        <span class="keyword">while</span>(!s.empty())
        {<span class="comment">//再次扫面看是否存在更大的矩形（例如测试样例2所示） </span>
            width+=s.top().w;
            curArea=s.top().h*width;
            <span class="keyword">if</span>(curArea&gt;ans)
                ans=curArea;
            s.pop();
        }
        <span class="built_in">printf</span>(<span class="string">"%d\n"</span>,ans);
    }
    <span class="keyword">return</span> <span class="number">0</span>;
} 
</code></pre>]]></content>
    <summary type="html">
    <![CDATA[<h1 id="题目链接">题目链接</h1><p><a href="http://poj.org/problem?id=2082" target="_blank" rel="external">Terrible Sets</a></p>
<h1 id="题目描述(Descrip]]>
    </summary>
    
      <category term="POJ" scheme="http://yoursite.com/tags/POJ/"/>
    
      <category term="Stack" scheme="http://yoursite.com/tags/Stack/"/>
    
      <category term="POJ" scheme="http://yoursite.com/categories/POJ/"/>
    
  </entry>
  
</feed>
